{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dba6a731",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Independent Tests for Bounding Box Validation on YOLO Model\n",
    "\n",
    "Using the Thermal Model for testing the Bounding Box Validation (BBV) Pipeline & Model on a live YOLO model, using manually counted clips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "639cb6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Dependencies '''\n",
    "# TODO Remove as not needed\n",
    "import importlib  # Refreshing imports\n",
    "\n",
    "# Core libraries\n",
    "import cv2\n",
    "import supervision as sv\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from utils.thermal_frame_to_temp import result_to_temp_frame\n",
    "import utils.group_bounding_boxes as group_and_merge_bounding_boxes\n",
    "from validate_bounding_box import get_box_count\n",
    "from tkinter.filedialog import askopenfilename, askdirectory\n",
    "import joblib\n",
    "from collections import Counter\n",
    "\n",
    "# SVM and model training\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Synthesizing Data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ANN\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Better exception handling and helpers\n",
    "import traceback\n",
    "import pprint\n",
    "import datetime\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cfd629",
   "metadata": {},
   "source": [
    "## Deriving Ground Truth Video & Labeling\n",
    "\n",
    "Given a clip with a known count, save the known count for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a03da080",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUE_COUNT = 122  # True count for the given clip\n",
    "FILE_NAME:str = \"3-Part-Mid-Belt-Testing-Clip-TRUE_COUNT-122\" # Global variable to store the selected file name if applicable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb15db2",
   "metadata": {},
   "source": [
    "## Pulling in the saved model & declaring pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7ffff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBV_MODEL = joblib.load('thermal_chick_counting_rf_model.pkl')  # Load the pre-trained BBV model\n",
    "YOLO_MODEL = YOLO('./models/new_iron.pt')  # Load the pre-trained YOLO model\n",
    "\n",
    "# Declare the pipeline\n",
    "BBV_PIPELINE = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', BBV_MODEL)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b40b613",
   "metadata": {},
   "source": [
    "## Run the YOLO Model with Thermal Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7740794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_from_video_frame(frame):\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    # Draw a horizontal line across the middle of the frame\n",
    "    line_start = (frame_width, frame_height // 2)\n",
    "    line_end = (0, frame_height // 2)\n",
    "    return [line_start, line_end]\n",
    "\n",
    "def chick_counting(video_path, output_path, line_points, verbose = False):\n",
    "\n",
    "    # Grab a sample frame so we know video size\n",
    "    generator = sv.get_video_frames_generator(video_path)\n",
    "    frame = next(generator)\n",
    "\n",
    "    # Set up video writer with same FPS/size as input\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame.shape[1], frame.shape[0]))\n",
    "    if not out.isOpened():\n",
    "        print(\"Error: Could not open video writer\")\n",
    "        return\n",
    "\n",
    "    # Init tracker and helpers\n",
    "    byte_tracker = sv.ByteTrack()\n",
    "    trace_annotator = sv.TraceAnnotator(thickness=4, trace_length=50)\n",
    "\n",
    "    # Create the counting line\n",
    "    line_zone = sv.LineZone(start=sv.Point(*line_points[0]), end=sv.Point(*line_points[1]))\n",
    "\n",
    "    # Load custom YOLO model\n",
    "    model = YOLO_MODEL\n",
    "\n",
    "    # Annotators for boxes + labels\n",
    "    BOUNDING_BOX_ANNOTATOR = sv.BoundingBoxAnnotator(thickness=2)\n",
    "    LABEL_ANNOTATOR = sv.LabelAnnotator(\n",
    "        text_thickness=2,\n",
    "        text_scale=1,\n",
    "        text_color=sv.Color.BLACK\n",
    "    )\n",
    "\n",
    "    frame_count = 0\n",
    "    total_count = 0\n",
    "    total_count_bbv = 0\n",
    "    all_counted_ids = set()  # keep track of already-counted trackers\n",
    "    all_counted_ids_bbv = set()  # Seperate list for the bounding box validation\n",
    "\n",
    "    try:\n",
    "        generator = sv.get_video_frames_generator(video_path)\n",
    "\n",
    "        for frame in generator:\n",
    "            frame_count += 1\n",
    "            if verbose:\n",
    "                print(f\"Processing frame {frame_count}\")\n",
    "\n",
    "            # Run YOLO on frame\n",
    "            results = model(frame)[0]\n",
    "            \n",
    "            # Get the frame image as denormalized numpy array\n",
    "            temp_arr: np.array = results_to_temp_frame(results)\n",
    "\n",
    "            # Convert results to supervision Detections\n",
    "            detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "            # Get indicies of all boxes\n",
    "            # Sensitivity for declaring a box as \"nested\" (e.g. 0.9 means inner must have at least 90% of its area inside outer)\n",
    "            NESTED_THRESHOLD = 0.9  \n",
    "\n",
    "            contained_indices = set()\n",
    "            boxes = detections.xyxy\n",
    "\n",
    "            for i, outer in enumerate(boxes):\n",
    "                x1o, y1o, x2o, y2o = outer\n",
    "                outer_area = max(0, (x2o - x1o)) * max(0, (y2o - y1o))\n",
    "\n",
    "                for j, inner in enumerate(boxes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    x1i, y1i, x2i, y2i = inner\n",
    "                    inner_area = max(0, (x2i - x1i)) * max(0, (y2i - y1i))\n",
    "\n",
    "                    # Intersection box\n",
    "                    inter_x1 = max(x1o, x1i)\n",
    "                    inter_y1 = max(y1o, y1i)\n",
    "                    inter_x2 = min(x2o, x2i)\n",
    "                    inter_y2 = min(y2o, y2i)\n",
    "\n",
    "                    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
    "\n",
    "                    # Ratio of inner covered by outer\n",
    "                    if inner_area > 0 and (inter_area / inner_area) >= NESTED_THRESHOLD:\n",
    "                        contained_indices.add(j)\n",
    "\n",
    "\n",
    "            # Update tracker with detections\n",
    "            detections = byte_tracker.update_with_detections(detections)\n",
    "            if verbose:\n",
    "                print(\"Tracker IDs this frame:\", detections.tracker_id)\n",
    "\n",
    "            # See if any trackers crossed the line\n",
    "            crossed_in_flags, crossed_out_flags = line_zone.trigger(detections)\n",
    "\n",
    "            # Only count new IDs that cross \"in\"\n",
    "            for i, crossed in enumerate(crossed_in_flags):\n",
    "                if crossed:\n",
    "                    tracker_id = detections.tracker_id[i]\n",
    "                    \n",
    "                    # YOLO tracker\n",
    "                    if tracker_id is not None and tracker_id not in all_counted_ids:\n",
    "                        total_count += 1\n",
    "                        all_counted_ids.add(tracker_id)\n",
    "                        if verbose:\n",
    "                            print(f\"New Chick crossed the line! ID {tracker_id}, Total count: {total_count}\")\n",
    "                    \n",
    "                    # Bounding Box Validation tracker\n",
    "                    if tracker_id is not None and tracker_id not in all_counted_ids_vbb:\n",
    "                        # Get the merged bounding boxes for overlaps in this frame\n",
    "                        merged_box_group, grouped_tracker_ids = group_and_merge_bounding_boxes(\n",
    "                            detections.xyxy, \n",
    "                            detections.tracker_id.tolist(), \n",
    "                            target_id=tracker_id\n",
    "                        )\n",
    "                        all_counted_ids_bbv.extend(grouped_tracker_ids)  # Add all grouped IDs to counted list\n",
    "                        # Using the merged group, add to the total BBV count\n",
    "                        total_count_bbv += get_box_count(\n",
    "                            temperature_frame=temp_arr,\n",
    "                            pipeline=BBV_PIPELINE,\n",
    "                            box=merged_box_group\n",
    "                        )\n",
    "                        if verbose:\n",
    "                            print(f\"New BBV Chick(s) crossed the line! Grouped IDs {grouped_tracker_ids}, BBV Total count: {total_count_bbv}\")\n",
    "\n",
    "            # Assign labels + colors depending on nesting\n",
    "            labels = []\n",
    "            colors = []\n",
    "            for i, tracker_id in enumerate(detections.tracker_id):\n",
    "                if i in contained_indices:\n",
    "                    labels.append(f\"#{tracker_id} nested\")\n",
    "                    colors.append(sv.Color.RED)\n",
    "                else:\n",
    "                    labels.append(f\"#{tracker_id} chick\")\n",
    "                    colors.append(sv.Color.GREEN)\n",
    "\n",
    "            # Draw tracker trails\n",
    "            annotated_frame = trace_annotator.annotate(scene=frame.copy(), detections=detections)\n",
    "\n",
    "            # Draw bounding boxes manually with chosen colors\n",
    "            for i, box in enumerate(detections.xyxy):\n",
    "                color = colors[i] if i < len(colors) else sv.Color.GREEN\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color.as_bgr(), 2)\n",
    "\n",
    "            # Draw labels\n",
    "            annotated_frame = LABEL_ANNOTATOR.annotate(annotated_frame, detections, labels=labels)\n",
    "\n",
    "            # Draw the counting line\n",
    "            cv2.line(annotated_frame, line_points[0], line_points[1], (0, 0, 255), 2)\n",
    "\n",
    "            # Overlay YOLO total count\n",
    "            cv2.putText(\n",
    "                annotated_frame,\n",
    "                f'Total Count: {total_count}',\n",
    "                (10, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 255, 0),\n",
    "                2,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "            # Overlay BBV total count\n",
    "            cv2.putText(\n",
    "                annotated_frame,\n",
    "                f'BBV Total Count: {total_count_bbv}',\n",
    "                (10, 80),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (255, 0, 0),\n",
    "                2,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "            # Overlay True total count\n",
    "            cv2.putText(\n",
    "                annotated_frame,\n",
    "                f'True Total Count: {TRUE_COUNT}',\n",
    "                (10, 110),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 0, 255),\n",
    "                2,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "\n",
    "            # Write out annotated frame\n",
    "            out.write(annotated_frame)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during processing: {e}\")\n",
    "\n",
    "    finally:\n",
    "        # Clean up writer and windows\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(f\"Total Frames Processed: {frame_count}\\nYOLO Count = {total_count}, BBV Total = {total_count_bbv}, True Count = {TRUE_COUNT}\")\n",
    "        if verbose:\n",
    "            print(f\"LineZone internal count (for reference): in={line_zone.in_count}, out={line_zone.out_count}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import tkinter as tk\n",
    "    from tkinter.filedialog import askopenfilename, askdirectory\n",
    "    tk.Tk().withdraw()\n",
    "\n",
    "    # Pick input video + output folder with file dialogs\n",
    "    SOURCE_VIDEO_PATH = askopenfilename()\n",
    "    print(\"User chose:\", SOURCE_VIDEO_PATH)\n",
    "\n",
    "    folder_path = askdirectory()\n",
    "    print(\"Output folder:\", folder_path)\n",
    "\n",
    "    # Build output filename\n",
    "    filename_no_ext = SOURCE_VIDEO_PATH.split('/')[-1].rsplit('.', 1)[0]\n",
    "    OUTPUT_PATH = f\"{folder_path}/{filename_no_ext}-outputfile(colored).mp4\"\n",
    "    print(\"Output path:\", OUTPUT_PATH)\n",
    "\n",
    "    # Grab a frame to define the line\n",
    "    cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read the video\")\n",
    "        exit()\n",
    "    cap.release()\n",
    "\n",
    "    line_points = get_line_from_video_frame(frame)\n",
    "    print(\"Line points:\", line_points)\n",
    "\n",
    "    # Only run if line points are valid\n",
    "    if len(line_points) == 2:\n",
    "        chick_counting(SOURCE_VIDEO_PATH, OUTPUT_PATH, line_points)\n",
    "    else:\n",
    "        print(\"Error: Not enough points to define the counting line.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
