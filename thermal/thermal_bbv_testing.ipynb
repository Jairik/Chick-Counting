{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dba6a731",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Independent Tests for Bounding Box Validation on YOLO Model\n",
    "\n",
    "Using the Thermal Model for testing the Bounding Box Validation (BBV) Pipeline & Model on a live YOLO model, using manually counted clips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41e50ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "# Run bash to install tkinter (requires sudo privileges and apt)\n",
    "!sudo apt-get update -y && sudo apt-get install -y python3-tk\n",
    "# Ensure that all dependencies are installed\n",
    "# Install 'uv' (if available), create a virtual environment, activate it in this shell,\n",
    "# then install requirements into that venv.\n",
    "%pip install uv || true\n",
    "%python3 -m venv .venv\n",
    "%. .venv/bin/activate && python -m pip install --upgrade pip setuptools wheel && python -m pip install uv && python -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "639cb6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Dependencies '''\n",
    "\n",
    "# Core libraries\n",
    "import cv2\n",
    "import supervision as sv\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from utils.thermal_frame_to_temp import result_to_temp_frame\n",
    "from utils.group_bounding_boxes import group_and_merge_bounding_boxes\n",
    "from validate_bounding_box import get_box_count\n",
    "from tkinter.filedialog import askopenfilename, askdirectory\n",
    "import joblib\n",
    "from collections import Counter\n",
    "\n",
    "# SVM and model training\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Synthesizing Data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ANN\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Better exception handling and helpers\n",
    "import traceback\n",
    "import pprint\n",
    "import datetime\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cfd629",
   "metadata": {},
   "source": [
    "## Deriving Ground Truth Video & Labeling\n",
    "\n",
    "Given a clip with a known count, save the known count for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a03da080",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUE_COUNT = 122  # True count for the given clip\n",
    "FILE_NAME:str = \"data/Brennen's-Thermal-Video/Top-Belt(Iron)-01-Testing-TRUE_COUNT-98.mp4\" # Global variable to store the selected file name if applicable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb15db2",
   "metadata": {},
   "source": [
    "## Pulling in the saved model & declaring pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7ffff57",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'thermal_chick_counting_rf_model_fit.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m BBV_MODEL = \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mthermal_chick_counting_rf_model_fit.pkl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Load the pre-trained BBV model\u001b[39;00m\n\u001b[32m      2\u001b[39m BBV_STANDARD_SCALER = joblib.load(\u001b[33m'\u001b[39m\u001b[33mthermal_chick_counting_rf_scaler.pkl\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# Load the pre-fitted StandardScaler\u001b[39;00m\n\u001b[32m      3\u001b[39m YOLO_MODEL = YOLO(\u001b[33m'\u001b[39m\u001b[33m./models/new_iron.pt\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# Load the pre-trained YOLO model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/JJ/Desktop/Repos/Chick-Counting/.venv/lib/python3.12/site-packages/joblib/numpy_pickle.py:735\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode, ensure_native_byte_order)\u001b[39m\n\u001b[32m    733\u001b[39m         obj = _unpickle(fobj, ensure_native_byte_order=ensure_native_byte_order)\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    736\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _validate_fileobject_and_memmap(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[32m    737\u001b[39m             fobj,\n\u001b[32m    738\u001b[39m             validated_mmap_mode,\n\u001b[32m    739\u001b[39m         ):\n\u001b[32m    740\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    741\u001b[39m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[32m    742\u001b[39m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[32m    743\u001b[39m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'thermal_chick_counting_rf_model_fit.pkl'"
     ]
    }
   ],
   "source": [
    "BBV_MODEL = joblib.load('thermal_chick_counting_rf_model_fit.pkl')  # Load the pre-trained BBV model\n",
    "BBV_STANDARD_SCALER = joblib.load('thermal_chick_counting_rf_scaler.pkl')  # Load the pre-fitted StandardScaler\n",
    "YOLO_MODEL = YOLO('./models/new_iron.pt')  # Load the pre-trained YOLO model\n",
    "\n",
    "# Declare the pipeline\n",
    "BBV_PIPELINE = Pipeline([\n",
    "    ('scaler', BBV_STANDARD_SCALER),\n",
    "    ('classifier', BBV_MODEL)\n",
    "])\n",
    "\n",
    "# Validate that the model properly loaded\n",
    "BBV_PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b40b613",
   "metadata": {},
   "source": [
    "## Run the YOLO Model with Thermal Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7740794",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def get_line_from_video_frame(frame):\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    # Draw a horizontal line across the middle of the frame\n",
    "    line_start = (frame_width, frame_height // 2)\n",
    "    line_end = (0, frame_height // 2)\n",
    "    return [line_start, line_end]\n",
    "\n",
    "def chick_counting(video_path, output_path, line_points, verbose = False):\n",
    "\n",
    "    # Grab a sample frame so we know video size\n",
    "    generator = sv.get_video_frames_generator(video_path)\n",
    "    frame = next(generator)\n",
    "\n",
    "    # Set up video writer with same FPS/size as input\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame.shape[1], frame.shape[0]))\n",
    "    if not out.isOpened():\n",
    "        print(\"Error: Could not open video writer\")\n",
    "        return\n",
    "\n",
    "    # Init tracker and helpers\n",
    "    byte_tracker = sv.ByteTrack()\n",
    "    trace_annotator = sv.TraceAnnotator(thickness=4, trace_length=50)\n",
    "\n",
    "    # Create the counting line\n",
    "    line_zone = sv.LineZone(start=sv.Point(*line_points[0]), end=sv.Point(*line_points[1]))\n",
    "\n",
    "    # Load custom YOLO model\n",
    "    model = YOLO_MODEL\n",
    "    \n",
    "    # Annotators for boxes + labels\n",
    "    BOUNDING_BOX_ANNOTATOR = sv.BoxAnnotator(thickness=2, color=sv.Color(0, 255, 0))\n",
    "    LABEL_ANNOTATOR = sv.LabelAnnotator(text_scale=1)\n",
    "\n",
    "    # Counters\n",
    "    frame_count = 0\n",
    "    total_count = 0\n",
    "    total_count_bbv = 0\n",
    "    all_counted_ids = set()  # keep track of already-counted trackers\n",
    "    all_counted_ids_bbv = set()  # Seperate list for the bounding box validation\n",
    "    \n",
    "    # Constants to hold high and low thermal temperatures for denormalization\n",
    "    prev_hi = None\n",
    "    prev_lo = None\n",
    "\n",
    "    try:\n",
    "        generator = sv.get_video_frames_generator(video_path)\n",
    "\n",
    "        for frame in generator:\n",
    "            frame_count += 1\n",
    "            if verbose:\n",
    "                print(f\"Processing frame {frame_count}\")\n",
    "\n",
    "            # Run YOLO on frame\n",
    "            results = model(frame)[0]\n",
    "            \n",
    "            # Get the frame image as denormalized numpy array\n",
    "            try:\n",
    "                temp_arr, prev_hi, prev_lo = result_to_temp_frame(\n",
    "                    results,\n",
    "                    frame_idx = frame_count,\n",
    "                    prev_hi_val = prev_hi,\n",
    "                    prev_lo_val = prev_lo\n",
    "                )\n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"Warning: Could not convert frame {frame_count} to temperature array. Skipping BBV for this frame.\")\n",
    "                if prev_hi is not None and prev_lo is not None:\n",
    "                    temp_arr = np.zeros_like(frame[..., 0], dtype=np.float32)  # reuse last temp_arr shape\n",
    "                else:\n",
    "                    temp_arr = None\n",
    "\n",
    "            # Convert results to supervision Detections\n",
    "            detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "            # Sensitivity for declaring a box as \"nested\" (e.g. 0.9 means inner must have at least 90% of its area inside outer)\n",
    "            NESTED_THRESHOLD = 0.9  \n",
    "\n",
    "            # Get indicies of all boxes\n",
    "            contained_indices = set()\n",
    "            boxes = detections.xyxy\n",
    "\n",
    "            for i, outer in enumerate(boxes):\n",
    "                x1o, y1o, x2o, y2o = outer\n",
    "                outer_area = max(0, (x2o - x1o)) * max(0, (y2o - y1o))\n",
    "\n",
    "                for j, inner in enumerate(boxes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    x1i, y1i, x2i, y2i = inner\n",
    "                    inner_area = max(0, (x2i - x1i)) * max(0, (y2i - y1i))\n",
    "\n",
    "                    # Intersection box\n",
    "                    inter_x1 = max(x1o, x1i)\n",
    "                    inter_y1 = max(y1o, y1i)\n",
    "                    inter_x2 = min(x2o, x2i)\n",
    "                    inter_y2 = min(y2o, y2i)\n",
    "\n",
    "                    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
    "\n",
    "                    # Ratio of inner covered by outer\n",
    "                    if inner_area > 0 and (inter_area / inner_area) >= NESTED_THRESHOLD:\n",
    "                        contained_indices.add(j)\n",
    "\n",
    "\n",
    "            # Update tracker with detections\n",
    "            detections = byte_tracker.update_with_detections(detections)\n",
    "            if verbose:\n",
    "                print(\"Tracker IDs this frame:\", detections.tracker_id)\n",
    "\n",
    "            # See if any trackers crossed the line\n",
    "            crossed_in_flags, crossed_out_flags = line_zone.trigger(detections)\n",
    "\n",
    "            # Only count new IDs that cross \"in\"\n",
    "            for i, crossed in enumerate(crossed_in_flags):\n",
    "                if crossed:\n",
    "                    tracker_id = detections.tracker_id[i]\n",
    "                    \n",
    "                    if tracker_id is None: continue  # Skip if no tracker ID\n",
    "                    \n",
    "                    # YOLO tracker\n",
    "                    if tracker_id not in all_counted_ids:\n",
    "                        total_count += 1\n",
    "                        all_counted_ids.add(tracker_id)\n",
    "                        if verbose:\n",
    "                            print(f\"New Chick crossed the line! ID {tracker_id}, Total count: {total_count}\")\n",
    "                    \n",
    "                    # Bounding Box Validation tracker\n",
    "                    if tracker_id not in all_counted_ids_bbv:\n",
    "                        # Get the merged bounding boxes for overlaps in this frame\n",
    "                        group_and_merge_bounding_boxes_result = group_and_merge_bounding_boxes(\n",
    "                            xyxy = detections.xyxy, \n",
    "                            tracker_ids = detections.tracker_id.tolist(), \n",
    "                            target_tracker_id = tracker_id,\n",
    "                            iou_thresh = 0.10,  # Low threshold to catch even slight overlaps\n",
    "                        )\n",
    "                        if group_and_merge_bounding_boxes_result is None: continue  # Skip if no valid group found\n",
    "                        merged_box_group, grouped_tracker_ids = group_and_merge_bounding_boxes_result\n",
    "                        all_counted_ids_bbv.update(grouped_tracker_ids)  # Add all grouped IDs to counted list\n",
    "                        # Using the merged group, add to the total BBV count\n",
    "                        total_count_bbv += get_box_count(\n",
    "                            pipeline=BBV_PIPELINE,\n",
    "                            temperature_frame=temp_arr,\n",
    "                            box=merged_box_group\n",
    "                        )\n",
    "                        if verbose:\n",
    "                            print(f\"New BBV Chick(s) crossed the line! Grouped IDs {grouped_tracker_ids}, BBV Total count: {total_count_bbv}\")\n",
    "\n",
    "            # Assign labels + colors depending on nesting\n",
    "            labels = []\n",
    "            colors = []\n",
    "            for i, tracker_id in enumerate(detections.tracker_id):\n",
    "                if i in contained_indices:\n",
    "                    labels.append(f\"#{tracker_id} nested\")\n",
    "                    colors.append(sv.Color.RED)\n",
    "                else:\n",
    "                    labels.append(f\"#{tracker_id} chick\")\n",
    "                    colors.append(sv.Color.GREEN)\n",
    "\n",
    "            # Draw tracker trails\n",
    "            annotated_frame = trace_annotator.annotate(scene=frame.copy(), detections=detections)\n",
    "\n",
    "            # Draw bounding boxes manually with chosen colors\n",
    "            for i, box in enumerate(detections.xyxy):\n",
    "                color = colors[i] if i < len(colors) else sv.Color.GREEN\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color.as_bgr(), 2)\n",
    "\n",
    "            # Draw labels\n",
    "            # Draw smaller labels with smaller background rectangles\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.4  # significantly smaller\n",
    "            thickness = 1\n",
    "            pad = 3\n",
    "\n",
    "            for i, lbl in enumerate(labels):\n",
    "                x1, y1, x2, y2 = map(int, detections.xyxy[i])\n",
    "                text_size, _ = cv2.getTextSize(lbl, font, font_scale, thickness)\n",
    "                text_w, text_h = text_size\n",
    "\n",
    "                # Position label above box if space, otherwise below\n",
    "                if y1 - text_h - 2 * pad > 0:\n",
    "                    rect_tl = (x1, y1 - text_h - 2 * pad)\n",
    "                    rect_br = (x1 + text_w + 2 * pad, y1)\n",
    "                    text_org = (x1 + pad, y1 - pad)\n",
    "                else:\n",
    "                    rect_tl = (x1, y1)\n",
    "                    rect_br = (x1 + text_w + 2 * pad, y1 + text_h + 2 * pad)\n",
    "                    text_org = (x1 + pad, y1 + text_h + pad)\n",
    "\n",
    "                # Background color: use tracker color if available, else black\n",
    "                bg_color = colors[i].as_bgr() if i < len(colors) else (0, 0, 0)\n",
    "                # Choose text color for contrast\n",
    "                text_color = (0, 0, 0) if sum(bg_color) > 382 else (255, 255, 255)\n",
    "\n",
    "                cv2.rectangle(annotated_frame, rect_tl, rect_br, bg_color, cv2.FILLED)\n",
    "                cv2.putText(annotated_frame, lbl, text_org, font, font_scale, text_color, thickness, cv2.LINE_AA)\n",
    "\n",
    "            # Draw the counting line\n",
    "            cv2.line(annotated_frame, line_points[0], line_points[1], (0, 0, 255), 2)\n",
    "\n",
    "            # Overlay YOLO total count\n",
    "            cv2.putText(\n",
    "                annotated_frame,\n",
    "                f'Total Count: {total_count}',\n",
    "                (10, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 255, 0),\n",
    "                2,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "            # Overlay BBV total count\n",
    "            cv2.putText(\n",
    "                annotated_frame,\n",
    "                f'BBV Total Count: {total_count_bbv}',\n",
    "                (10, 80),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (255, 0, 0),\n",
    "                2,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "            # Overlay True total count\n",
    "            cv2.putText(\n",
    "                annotated_frame,\n",
    "                f'True Total Count: {TRUE_COUNT}',\n",
    "                (10, 110),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 0, 255),\n",
    "                2,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "\n",
    "            # Write out annotated frame\n",
    "            out.write(annotated_frame)\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Detailed exception logging\n",
    "        print(\"=== Exception while processing video frames ===\")\n",
    "        print(\"Time:\", datetime.datetime.now().isoformat())\n",
    "        print(\"Exception type:\", type(e).__name__)\n",
    "        print(\"Exception message:\", str(e))\n",
    "        print(\"Full traceback:\")\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "    finally:\n",
    "        # Clean up writer and windows\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(f\"Total Frames Processed: {frame_count}\\nYOLO Count = {total_count}, BBV Total = {total_count_bbv}, True Count = {TRUE_COUNT}\")\n",
    "        if verbose:\n",
    "            print(f\"LineZone internal count (for reference): in={line_zone.in_count}, out={line_zone.out_count}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import tkinter as tk\n",
    "    from tkinter.filedialog import askopenfilename, askdirectory\n",
    "    tk.Tk().withdraw()\n",
    "\n",
    "    # Pick input video + output folder with file dialogs\n",
    "    SOURCE_VIDEO_PATH = askopenfilename()\n",
    "    print(\"User chose:\", SOURCE_VIDEO_PATH)\n",
    "\n",
    "    folder_path = askdirectory()\n",
    "    print(\"Output folder:\", folder_path)\n",
    "\n",
    "    # Build output filename\n",
    "    filename_no_ext = SOURCE_VIDEO_PATH.split('/')[-1].rsplit('.', 1)[0]\n",
    "    OUTPUT_PATH = f\"{folder_path}/{filename_no_ext}-outputfile(colored).mp4\"\n",
    "    print(\"Output path:\", OUTPUT_PATH)\n",
    "\n",
    "    # Grab a frame to define the line\n",
    "    cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read the video\")\n",
    "        exit()\n",
    "    cap.release()\n",
    "\n",
    "    line_points = get_line_from_video_frame(frame)\n",
    "    print(\"Line points:\", line_points)\n",
    "\n",
    "    # Only run if line points are valid\n",
    "    if len(line_points) == 2:\n",
    "        chick_counting(SOURCE_VIDEO_PATH, OUTPUT_PATH, line_points, verbose=True)\n",
    "    else:\n",
    "        print(\"Error: Not enough points to define the counting line.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5280d8",
   "metadata": {},
   "source": [
    "## BBV Pipeline v2 - No Bounding Box Grouping\n",
    "\n",
    "Similar to the functionality above, however this will use a model that is trained on singular bounding boxes (no grouping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3082a59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 RandomForestClassifier(max_depth=10, max_features=0.8,\n",
       "                                        min_samples_split=4))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('steps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">steps&nbsp;</td>\n",
       "            <td class=\"value\">[(&#x27;scaler&#x27;, ...), (&#x27;classifier&#x27;, ...)]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transform_input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">transform_input&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('memory',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">memory&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"scaler__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">copy&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_mean',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">with_mean&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_std',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">with_std&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"classifier__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">4</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">0.8</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">bootstrap&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">oob_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_samples&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotonic_cst&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('classifier',\n",
       "                 RandomForestClassifier(max_depth=10, max_features=0.8,\n",
       "                                        min_samples_split=4))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Determine video/clip to test '''\n",
    "TRUE_COUNT = 100  # True count for the given clip\n",
    "\n",
    "''' Load the relevant models and scalers '''\n",
    "BBV_MODEL_NO_GROUPING = joblib.load('./models/thermal_chick_counting_rf_model_fit.pkl')  # Load the pre-trained BBV model\n",
    "BBV_STANDARD_SCALER_NO_GROUPING = joblib.load('./models/thermal_chick_counting_rf_scaler.pkl')  # Load the pre-fitted StandardScaler\n",
    "YOLO_MODEL = YOLO('./models/new_iron.pt')  # Load the pre-trained YOLO model\n",
    "\n",
    "# Declare the pipeline\n",
    "BBV_PIPELINE_NO_GROUPING = Pipeline([\n",
    "    ('scaler', BBV_STANDARD_SCALER_NO_GROUPING),\n",
    "    ('classifier', BBV_MODEL_NO_GROUPING)\n",
    "])\n",
    "\n",
    "# Validate that the model properly loaded\n",
    "BBV_PIPELINE_NO_GROUPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c89e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User chose: /mnt/c/Users/JJ/Desktop/Repos/Chick-Counting/thermal/misc/BBV_Tests/Top Belt(Iron) 02 (1) - TEST1 TRUE 100.mp4\n",
      "Output folder: /mnt/c/Users/JJ/Desktop/Repos/Chick-Counting/thermal/misc/BBV_Tests\n",
      "Output path: /mnt/c/Users/JJ/Desktop/Repos/Chick-Counting/thermal/misc/BBV_Tests/Top Belt(Iron) 02 (1) - TEST1 TRUE 100-outputfile(colored).mp4\n",
      "Line points: [(256, 171), (0, 171)]\n",
      "Processing frame 1\n",
      "\n",
      "0: 640x480 26 Chicks, 20.6ms\n",
      "Speed: 4.9ms preprocess, 20.6ms inference, 53.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25]\n",
      "Processing frame 2\n",
      "\n",
      "0: 640x480 25 Chicks, 11.2ms\n",
      "Speed: 1.5ms preprocess, 11.2ms inference, 39.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 4 12  1 14  3  5  2 17 11  8 16 18  7 10 15  6  9 19 23 13 21 22 20 24 25]\n",
      "Processing frame 3\n",
      "\n",
      "0: 640x480 26 Chicks, 11.1ms\n",
      "Speed: 1.8ms preprocess, 11.1ms inference, 50.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 4  8  5 11  1 12 16 15  7  6  3 19 10 18  2 17 14 23 22  9 21 13 24 20]\n",
      "Processing frame 4\n",
      "\n",
      "0: 640x480 25 Chicks, 10.0ms\n",
      "Speed: 2.1ms preprocess, 10.0ms inference, 37.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 4  1  2  5  8  7 15 11 12 16  6 10 19 14  3 18 23 13 21 17 22  9 24]\n",
      "Processing frame 5\n",
      "\n",
      "0: 640x480 25 Chicks, 11.7ms\n",
      "Speed: 1.7ms preprocess, 11.7ms inference, 35.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 4  6  7 11  2  8  5  1 19 16 13 18 12 15 17 10 23 21 14 22  3 24]\n",
      "Processing frame 6\n",
      "\n",
      "0: 640x480 23 Chicks, 10.6ms\n",
      "Speed: 1.8ms preprocess, 10.6ms inference, 49.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 5  2  8 11  4  6  1  7 16 15 10 19 13 12 23 18 17  3 24 21]\n",
      "Processing frame 7\n",
      "\n",
      "0: 640x480 22 Chicks, 11.4ms\n",
      "Speed: 2.0ms preprocess, 11.4ms inference, 43.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 6  2 19 11  1  5  4  7 16  8 12 15 17 13 23 18 10 24 21 30]\n",
      "Processing frame 8\n",
      "\n",
      "0: 640x480 23 Chicks, 16.1ms\n",
      "Speed: 3.3ms preprocess, 16.1ms inference, 50.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [15  4  7  5 16  8  2  6  1 11 19 12 18 17 13 22 23 21 24]\n",
      "Processing frame 9\n",
      "\n",
      "0: 640x480 23 Chicks, 16.5ms\n",
      "Speed: 5.0ms preprocess, 16.5ms inference, 38.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 5  7  4 15 19 16  2  1 11  8  6 12 18 21 23 17 13 32 24]\n",
      "Processing frame 10\n",
      "\n",
      "0: 640x480 24 Chicks, 9.3ms\n",
      "Speed: 2.0ms preprocess, 9.3ms inference, 26.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 6  1  5  8  2 15 11  4 19  7 16 23 12 18 13 21 32 34 24]\n",
      "Processing frame 11\n",
      "\n",
      "0: 640x480 22 Chicks, 9.3ms\n",
      "Speed: 2.1ms preprocess, 9.3ms inference, 28.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 5  2 16  1 11 18  6  8 19  7 23  4 24 15 21 34 13 12]\n",
      "Processing frame 12\n",
      "\n",
      "0: 640x480 22 Chicks, 10.5ms\n",
      "Speed: 1.6ms preprocess, 10.5ms inference, 24.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 5 16 11  2  8  7  1 19  4  6 13 18 23 42 34 15 24 21]\n",
      "New Chick crossed the line! ID 4, Chicks in bounding box: 1, Total YOLO count: 1, Total BBV count: 1\n",
      "New Chick crossed the line! ID 6, Chicks in bounding box: 1, Total YOLO count: 2, Total BBV count: 2\n",
      "Processing frame 13\n",
      "\n",
      "0: 640x480 23 Chicks, 14.2ms\n",
      "Speed: 1.7ms preprocess, 14.2ms inference, 26.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 2  6  8 19  5 16  1 18 13 11  7 23  4 22 42 34 21]\n",
      "Processing frame 14\n",
      "\n",
      "0: 640x480 21 Chicks, 12.1ms\n",
      "Speed: 1.7ms preprocess, 12.1ms inference, 22.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 5  8 11 18 16  2  6 22 19  4 13  1 42 23  7 21 45]\n",
      "Processing frame 15\n",
      "\n",
      "0: 640x480 22 Chicks, 9.2ms\n",
      "Speed: 1.4ms preprocess, 9.2ms inference, 23.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 5  6 22 18  2 19 30 11  4  7 42 24 16 13 23 21 45  1]\n",
      "Processing frame 16\n",
      "\n",
      "0: 640x480 21 Chicks, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 20.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [22  6 18  2  5 11  4 19 30 42 23  7 13 16  1 21]\n",
      "Processing frame 17\n",
      "\n",
      "0: 640x480 21 Chicks, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 22.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 5 18  6 11  4  2 22 19 42 13  7 23 21  1 30 24]\n",
      "Processing frame 18\n",
      "\n",
      "0: 640x480 20 Chicks, 9.6ms\n",
      "Speed: 1.6ms preprocess, 9.6ms inference, 24.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 5 11  6 22  4 18 19  2 23 13  7 42 21 24  1]\n",
      "Processing frame 19\n",
      "\n",
      "0: 640x480 20 Chicks, 9.5ms\n",
      "Speed: 1.5ms preprocess, 9.5ms inference, 20.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 6 11  5 19  4 22  7 18 13  2 42  1 23 21 24]\n",
      "New Chick crossed the line! ID 19, Chicks in bounding box: 1, Total YOLO count: 3, Total BBV count: 3\n",
      "Processing frame 20\n",
      "\n",
      "0: 640x480 18 Chicks, 20.2ms\n",
      "Speed: 2.4ms preprocess, 20.2ms inference, 19.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 5  6 19  4 18  2 13 23 22  7 24 11  1 21 42]\n",
      "New Chick crossed the line! ID 23, Chicks in bounding box: 1, Total YOLO count: 4, Total BBV count: 4\n",
      "Processing frame 21\n",
      "\n",
      "0: 640x480 18 Chicks, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 21.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [19  6  5 13  2  4 18  1 23 22 42 21 24 11  7]\n",
      "Processing frame 22\n",
      "\n",
      "0: 640x480 18 Chicks, 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 23.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [19  1  4  6 13  5 22 18 23  2 11 42 21 24]\n",
      "Processing frame 23\n",
      "\n",
      "0: 640x480 17 Chicks, 9.8ms\n",
      "Speed: 1.5ms preprocess, 9.8ms inference, 19.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 2 18  4  5 34 22 11 13 19 23  1 42 21  6 24]\n",
      "New Chick crossed the line! ID 18, Chicks in bounding box: 1, Total YOLO count: 5, Total BBV count: 5\n",
      "Processing frame 24\n",
      "\n",
      "0: 640x480 17 Chicks, 9.4ms\n",
      "Speed: 1.6ms preprocess, 9.4ms inference, 25.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [19  5 13 22  6 11 18  2 34  4 24 42 23 21  1]\n",
      "Processing frame 25\n",
      "\n",
      "0: 640x480 17 Chicks, 10.2ms\n",
      "Speed: 1.4ms preprocess, 10.2ms inference, 27.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [19 22  2  6 34 11  5 18  4 21 24 23 13 42  1]\n",
      "Processing frame 26\n",
      "\n",
      "0: 640x480 17 Chicks, 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 21.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [19  6 22  5 34 11  4 23 42 13 24  2 18 21  1]\n",
      "Processing frame 27\n",
      "\n",
      "0: 640x480 20 Chicks, 10.8ms\n",
      "Speed: 1.8ms preprocess, 10.8ms inference, 20.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 6 22  4  5 34 11 19 24 13 18 23 42 21  2  1]\n",
      "New Chick crossed the line! ID 5, Chicks in bounding box: 1, Total YOLO count: 6, Total BBV count: 6\n",
      "New Chick crossed the line! ID 21, Chicks in bounding box: 1, Total YOLO count: 7, Total BBV count: 7\n",
      "Processing frame 28\n",
      "\n",
      "0: 640x480 20 Chicks, 9.6ms\n",
      "Speed: 1.7ms preprocess, 9.6ms inference, 27.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 4 22  6 11 19  5 34 24 21 42 23 13 53 18 54]\n",
      "New Chick crossed the line! ID 24, Chicks in bounding box: 1, Total YOLO count: 8, Total BBV count: 8\n",
      "Processing frame 29\n",
      "\n",
      "0: 640x480 19 Chicks, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 21.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [22 11 19  6 18  5 34 21 24 42  4 23 13 53 54]\n",
      "Processing frame 30\n",
      "\n",
      "0: 640x480 18 Chicks, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 22.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [11 13 45 21  6 32  5 34 24  4 22 19 18 23 53 42 56]\n",
      "Processing frame 31\n",
      "\n",
      "0: 640x480 18 Chicks, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 19.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [11  6 13 18 45 22 19 32 21 34  4  5 24 42 23 53]\n",
      "Processing frame 32\n",
      "\n",
      "0: 640x480 19 Chicks, 9.4ms\n",
      "Speed: 1.5ms preprocess, 9.4ms inference, 18.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [13  6 11 21 19  5 22  4 18 24 45 32 23 34 42 56]\n",
      "Processing frame 33\n",
      "\n",
      "0: 640x480 18 Chicks, 9.5ms\n",
      "Speed: 1.5ms preprocess, 9.5ms inference, 17.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [19 13 11 45  6 23  5 32 21 18 34 24  4 22 42]\n",
      "Processing frame 34\n",
      "\n",
      "0: 640x480 19 Chicks, 9.0ms\n",
      "Speed: 1.6ms preprocess, 9.0ms inference, 21.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [13 11  6 19 22 32 18 24  5 23 21 45  4 34 42]\n",
      "Processing frame 35\n",
      "\n",
      "0: 640x480 19 Chicks, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 20.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [11 19  5  6 18 32 22 13 23 45 34 24 42 21]\n",
      "Processing frame 36\n",
      "\n",
      "0: 640x480 18 Chicks, 9.8ms\n",
      "Speed: 1.6ms preprocess, 9.8ms inference, 18.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [19 34  6  5 11 21 24 23 32 18 22 45 42 56]\n",
      "Processing frame 37\n",
      "\n",
      "0: 640x480 16 Chicks, 9.9ms\n",
      "Speed: 1.4ms preprocess, 9.9ms inference, 18.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [19 11  5  6 22 18 24 21 34 23 32 45 42 13]\n",
      "Processing frame 38\n",
      "\n",
      "0: 640x480 18 Chicks, 10.2ms\n",
      "Speed: 1.5ms preprocess, 10.2ms inference, 29.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [11 19  5  6 18 24 22 23 45 32 34 21 42]\n",
      "Processing frame 39\n",
      "\n",
      "0: 640x480 16 Chicks, 12.7ms\n",
      "Speed: 1.6ms preprocess, 12.7ms inference, 22.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [11 19  5 18 23  6 22 45 32 24 42 34 21]\n",
      "Processing frame 40\n",
      "\n",
      "0: 640x480 17 Chicks, 16.2ms\n",
      "Speed: 1.6ms preprocess, 16.2ms inference, 22.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [11 18 19  5 22 24 32 45 42 21  6 23 34]\n",
      "Processing frame 41\n",
      "\n",
      "0: 640x480 16 Chicks, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 19.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 5 18 11 32 22 45 24 19 42  6 21 34 23]\n",
      "Processing frame 42\n",
      "\n",
      "0: 640x480 16 Chicks, 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 19.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [18  5 22 24 32  6 45 23 11 21 19 42 34]\n",
      "Processing frame 43\n",
      "\n",
      "0: 640x480 16 Chicks, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 16.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [18 24  5 22  6 45 32 21 42 34]\n",
      "Processing frame 44\n",
      "\n",
      "0: 640x480 15 Chicks, 10.1ms\n",
      "Speed: 1.4ms preprocess, 10.1ms inference, 17.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [24  5 22 32 18 45  6 42 34 21 23]\n",
      "New Chick crossed the line! ID 22, Chicks in bounding box: 1, Total YOLO count: 9, Total BBV count: 9\n",
      "Processing frame 45\n",
      "\n",
      "0: 640x480 14 Chicks, 9.1ms\n",
      "Speed: 1.7ms preprocess, 9.1ms inference, 17.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [42  5 22 34 24 32 45 18 21  6 65]\n",
      "Processing frame 46\n",
      "\n",
      "0: 640x480 15 Chicks, 9.2ms\n",
      "Speed: 1.5ms preprocess, 9.2ms inference, 17.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54 42 32 22 45  5 34  6 24 21 65]\n",
      "Processing frame 47\n",
      "\n",
      "0: 640x480 14 Chicks, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 15.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 5 54 22 42 45 32  6 34]\n",
      "New Chick crossed the line! ID 34, Chicks in bounding box: 1, Total YOLO count: 10, Total BBV count: 10\n",
      "Processing frame 48\n",
      "\n",
      "0: 640x480 13 Chicks, 8.9ms\n",
      "Speed: 2.1ms preprocess, 8.9ms inference, 15.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 5 54 22 32  6 45 42 34 24]\n",
      "New Chick crossed the line! ID 32, Chicks in bounding box: 1, Total YOLO count: 11, Total BBV count: 11\n",
      "Processing frame 49\n",
      "\n",
      "0: 640x480 11 Chicks, 10.9ms\n",
      "Speed: 2.2ms preprocess, 10.9ms inference, 13.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54  5 45  6 42 32 22 34 72 71]\n",
      "Processing frame 50\n",
      "\n",
      "0: 640x480 12 Chicks, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 6  5 22 45 54 32 42 34 72 71]\n",
      "New Chick crossed the line! ID 42, Chicks in bounding box: 1, Total YOLO count: 12, Total BBV count: 12\n",
      "Processing frame 51\n",
      "\n",
      "0: 640x480 11 Chicks, 10.4ms\n",
      "Speed: 2.0ms preprocess, 10.4ms inference, 14.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54 32 42 22 34  6 45 72  5 71]\n",
      "Processing frame 52\n",
      "\n",
      "0: 640x480 11 Chicks, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 15.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54 45 42 32  6 34 22 72 71]\n",
      "Processing frame 53\n",
      "\n",
      "0: 640x480 10 Chicks, 9.3ms\n",
      "Speed: 1.5ms preprocess, 9.3ms inference, 12.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54  6 34 42 45 22 32 53 71 72]\n",
      "New Chick crossed the line! ID 45, Chicks in bounding box: 1, Total YOLO count: 13, Total BBV count: 13\n",
      "Processing frame 54\n",
      "\n",
      "0: 640x480 12 Chicks, 9.1ms\n",
      "Speed: 1.6ms preprocess, 9.1ms inference, 14.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [42 45 54 32  6 53 22 34]\n",
      "Processing frame 55\n",
      "\n",
      "0: 640x480 12 Chicks, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 13.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [42 54  6 45 34 22 53 32]\n",
      "Processing frame 56\n",
      "\n",
      "0: 640x480 13 Chicks, 9.4ms\n",
      "Speed: 1.4ms preprocess, 9.4ms inference, 13.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54  6 45 42 22 32 53 34 74 73]\n",
      "Processing frame 57\n",
      "\n",
      "0: 640x480 13 Chicks, 9.0ms\n",
      "Speed: 1.7ms preprocess, 9.0ms inference, 13.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [42 22 53  6 54 74 45 32 73 34]\n",
      "Processing frame 58\n",
      "\n",
      "0: 640x480 13 Chicks, 9.0ms\n",
      "Speed: 1.8ms preprocess, 9.0ms inference, 16.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54 42 32 53 74 22 45 73  6 34 77 78]\n",
      "Processing frame 59\n",
      "\n",
      "0: 640x480 13 Chicks, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [42 32 53  6 54 45 22 74 73 34 77 78]\n",
      "Processing frame 60\n",
      "\n",
      "0: 640x480 13 Chicks, 9.7ms\n",
      "Speed: 1.4ms preprocess, 9.7ms inference, 13.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [53 54 42 45 32 34 22 73  6 74 77]\n",
      "Processing frame 61\n",
      "\n",
      "0: 640x480 13 Chicks, 25.0ms\n",
      "Speed: 1.8ms preprocess, 25.0ms inference, 21.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54 42 53 45  6 22 32 74 34 71 73]\n",
      "Processing frame 62\n",
      "\n",
      "0: 640x480 14 Chicks, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 17.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [42 45 53 54  6 32 74 73 34 22 71 79]\n",
      "Processing frame 63\n",
      "\n",
      "0: 640x480 14 Chicks, 9.1ms\n",
      "Speed: 1.8ms preprocess, 9.1ms inference, 15.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [42 53 32 54 45  6 22 34 71 74 73 79 80]\n",
      "Processing frame 64\n",
      "\n",
      "0: 640x480 14 Chicks, 9.5ms\n",
      "Speed: 1.7ms preprocess, 9.5ms inference, 15.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54 42 45 53  6 34 32 73 22 74 79 71 80]\n",
      "Processing frame 65\n",
      "\n",
      "0: 640x480 14 Chicks, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 16.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54 53 32  6 71 42 34 45 22 74 73 80]\n",
      "New Chick crossed the line! ID 53, Chicks in bounding box: 1, Total YOLO count: 14, Total BBV count: 14\n",
      "Processing frame 66\n",
      "\n",
      "0: 640x480 14 Chicks, 9.5ms\n",
      "Speed: 1.5ms preprocess, 9.5ms inference, 16.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [53 42 54 77 32 34 73 74 71  6 45 22 80]\n",
      "Processing frame 67\n",
      "\n",
      "0: 640x480 14 Chicks, 9.1ms\n",
      "Speed: 1.7ms preprocess, 9.1ms inference, 15.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54 42 53 32 77 74 34 71 22 73 45  6 80]\n",
      "Processing frame 68\n",
      "\n",
      "0: 640x480 14 Chicks, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 17.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54 53 42 32 22 73 34 71 74 77 45  6]\n",
      "Processing frame 69\n",
      "\n",
      "0: 640x480 15 Chicks, 10.2ms\n",
      "Speed: 1.6ms preprocess, 10.2ms inference, 15.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [71 53 54 32 74 42 45 34 73 22 77 81  6]\n",
      "New Chick crossed the line! ID 54, Chicks in bounding box: 1, Total YOLO count: 15, Total BBV count: 15\n",
      "Processing frame 70\n",
      "\n",
      "0: 640x480 14 Chicks, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [53 54 42 71 32 74 45 73 77 34 22 82 81]\n",
      "Processing frame 71\n",
      "\n",
      "0: 640x480 13 Chicks, 9.0ms\n",
      "Speed: 1.6ms preprocess, 9.0ms inference, 15.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54 32 53 42 73 79 74 71 77 45 34 22]\n",
      "Processing frame 72\n",
      "\n",
      "0: 640x480 13 Chicks, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 14.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54 32 79 53 73 77 74 45 71 42]\n",
      "Processing frame 73\n",
      "\n",
      "0: 640x480 12 Chicks, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 14.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [32 53 54 45 79 77 74 73 71]\n",
      "Processing frame 74\n",
      "\n",
      "0: 640x480 12 Chicks, 9.5ms\n",
      "Speed: 1.6ms preprocess, 9.5ms inference, 19.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54 53 79 73 77 74 32 45 71 84 42]\n",
      "Processing frame 75\n",
      "\n",
      "0: 640x480 13 Chicks, 9.4ms\n",
      "Speed: 1.4ms preprocess, 9.4ms inference, 14.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54 53 45 79 77 74 73 32 71 42 84]\n",
      "Processing frame 76\n",
      "\n",
      "0: 640x480 12 Chicks, 9.1ms\n",
      "Speed: 1.6ms preprocess, 9.1ms inference, 13.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [73 53 54 79 77 74 45 71 84]\n",
      "Processing frame 77\n",
      "\n",
      "0: 640x480 12 Chicks, 9.6ms\n",
      "Speed: 1.3ms preprocess, 9.6ms inference, 12.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [53 73 45 79 54 77 74 71]\n",
      "Processing frame 78\n",
      "\n",
      "0: 640x480 10 Chicks, 9.0ms\n",
      "Speed: 1.6ms preprocess, 9.0ms inference, 12.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [45 54 53 73 74 79 77 85 71]\n",
      "Processing frame 79\n",
      "\n",
      "0: 640x480 10 Chicks, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 13.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54 73 53 74 79 71 77 45 85]\n",
      "Processing frame 80\n",
      "\n",
      "0: 640x480 10 Chicks, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 12.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [73 54 79 77 74 53 85 71 45]\n",
      "Processing frame 81\n",
      "\n",
      "0: 640x480 12 Chicks, 9.4ms\n",
      "Speed: 1.7ms preprocess, 9.4ms inference, 12.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54 73 85 74 53 79 77 71]\n",
      "Processing frame 82\n",
      "\n",
      "0: 640x480 10 Chicks, 9.4ms\n",
      "Speed: 1.4ms preprocess, 9.4ms inference, 12.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54 73 77 53 79 85 74 71 88]\n",
      "Processing frame 83\n",
      "\n",
      "0: 640x480 10 Chicks, 9.1ms\n",
      "Speed: 1.4ms preprocess, 9.1ms inference, 11.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [85 73 77 54 79 53 74 71 88]\n",
      "Processing frame 84\n",
      "\n",
      "0: 640x480 11 Chicks, 9.4ms\n",
      "Speed: 1.4ms preprocess, 9.4ms inference, 18.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [73 54 74 53 77 79 71 85 88]\n",
      "Processing frame 85\n",
      "\n",
      "0: 640x480 11 Chicks, 9.2ms\n",
      "Speed: 1.5ms preprocess, 9.2ms inference, 12.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [73 54 53 85 74 77 79 71 89]\n",
      "New Chick crossed the line! ID 74, Chicks in bounding box: 1, Total YOLO count: 16, Total BBV count: 16\n",
      "Processing frame 86\n",
      "\n",
      "0: 640x480 11 Chicks, 23.4ms\n",
      "Speed: 1.7ms preprocess, 23.4ms inference, 35.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [85 73 54 53 71 77 74 79 89]\n",
      "Processing frame 87\n",
      "\n",
      "0: 640x480 11 Chicks, 9.7ms\n",
      "Speed: 1.4ms preprocess, 9.7ms inference, 12.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [53 54 73 71 74 77 79 85 84]\n",
      "New Chick crossed the line! ID 73, Chicks in bounding box: 1, Total YOLO count: 17, Total BBV count: 17\n",
      "New Chick crossed the line! ID 71, Chicks in bounding box: 1, Total YOLO count: 18, Total BBV count: 18\n",
      "Processing frame 88\n",
      "\n",
      "0: 640x480 11 Chicks, 9.3ms\n",
      "Speed: 2.0ms preprocess, 9.3ms inference, 15.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [54 85 77 74 79 84 73 53 71]\n",
      "Processing frame 89\n",
      "\n",
      "0: 640x480 13 Chicks, 9.4ms\n",
      "Speed: 1.6ms preprocess, 9.4ms inference, 16.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [71 85 73 74 77 54 79 84 82]\n",
      "Processing frame 90\n",
      "\n",
      "0: 640x480 14 Chicks, 9.9ms\n",
      "Speed: 1.8ms preprocess, 9.9ms inference, 18.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [73 54 77 84 74 85 79 71 90]\n",
      "Processing frame 91\n",
      "\n",
      "0: 640x480 13 Chicks, 10.3ms\n",
      "Speed: 1.7ms preprocess, 10.3ms inference, 17.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [74 73 71 54 85 84 77 79 90]\n",
      "Processing frame 92\n",
      "\n",
      "0: 640x480 12 Chicks, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 20.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [77 74 73 79 85 71 84 54]\n",
      "Processing frame 93\n",
      "\n",
      "0: 640x480 11 Chicks, 16.1ms\n",
      "Speed: 1.6ms preprocess, 16.1ms inference, 22.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [74 77 73 79 84 85 71]\n",
      "Processing frame 94\n",
      "\n",
      "0: 640x480 11 Chicks, 22.0ms\n",
      "Speed: 2.0ms preprocess, 22.0ms inference, 19.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [73 74 88 77 85 84 79 71]\n",
      "New Chick crossed the line! ID 77, Chicks in bounding box: 1, Total YOLO count: 19, Total BBV count: 19\n",
      "Processing frame 95\n",
      "\n",
      "0: 640x480 11 Chicks, 18.7ms\n",
      "Speed: 2.7ms preprocess, 18.7ms inference, 14.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [73 74 77 85 84 88 79 71]\n",
      "Processing frame 96\n",
      "\n",
      "0: 640x480 11 Chicks, 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 12.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [74 73 77 88 79 85 84 71 94]\n",
      "Processing frame 97\n",
      "\n",
      "0: 640x480 13 Chicks, 9.3ms\n",
      "Speed: 1.5ms preprocess, 9.3ms inference, 19.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [74 85 77 88 73 79 84 71 94]\n",
      "New Chick crossed the line! ID 79, Chicks in bounding box: 1, Total YOLO count: 20, Total BBV count: 20\n",
      "Processing frame 98\n",
      "\n",
      "0: 640x480 13 Chicks, 9.0ms\n",
      "Speed: 1.6ms preprocess, 9.0ms inference, 17.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [77 89 85 79 73 84 88 71 74]\n",
      "Processing frame 99\n",
      "\n",
      "0: 640x480 16 Chicks, 9.9ms\n",
      "Speed: 1.7ms preprocess, 9.9ms inference, 18.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [77 88 84 79 73 96 85 89 71 74 99 97]\n",
      "Processing frame 100\n",
      "\n",
      "0: 640x480 17 Chicks, 9.7ms\n",
      "Speed: 1.6ms preprocess, 9.7ms inference, 24.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 85  96  79  89  77  88  84  73  74  99  71  97 101]\n",
      "Processing frame 101\n",
      "\n",
      "0: 640x480 17 Chicks, 10.5ms\n",
      "Speed: 2.1ms preprocess, 10.5ms inference, 43.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 77  96  85  99  89  74  73  88  79  84 101  71 103  97]\n",
      "Processing frame 102\n",
      "\n",
      "0: 640x480 17 Chicks, 9.3ms\n",
      "Speed: 1.8ms preprocess, 9.3ms inference, 22.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 96  77  88  89  79  74  73  84  85 101  71 103 104]\n",
      "Processing frame 103\n",
      "\n",
      "0: 640x480 17 Chicks, 9.9ms\n",
      "Speed: 1.6ms preprocess, 9.9ms inference, 21.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 77  96  88  79  84  89  85  73 101  71  74 103 104]\n",
      "Processing frame 104\n",
      "\n",
      "0: 640x480 17 Chicks, 9.0ms\n",
      "Speed: 1.7ms preprocess, 9.0ms inference, 20.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 96  79  77  71  85  84  89  88 101 103 104  74]\n",
      "New Chick crossed the line! ID 85, Chicks in bounding box: 1, Total YOLO count: 21, Total BBV count: 21\n",
      "Processing frame 105\n",
      "\n",
      "0: 640x480 16 Chicks, 10.1ms\n",
      "Speed: 2.7ms preprocess, 10.1ms inference, 21.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 85  96  88  79  74  77  89  71  73  84 101 103]\n",
      "Processing frame 106\n",
      "\n",
      "0: 640x480 19 Chicks, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 21.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 77  71  79  88  96  74  84  89  85 101 103  73]\n",
      "Processing frame 107\n",
      "\n",
      "0: 640x480 18 Chicks, 9.2ms\n",
      "Speed: 1.7ms preprocess, 9.2ms inference, 21.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 71  79 101  77  96  74  84  85  88  89 103  73]\n",
      "Processing frame 108\n",
      "\n",
      "0: 640x480 19 Chicks, 14.6ms\n",
      "Speed: 1.6ms preprocess, 14.6ms inference, 20.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 71  73  96  85  89  79 101  88  84  77  74 103 109 108 110]\n",
      "Processing frame 109\n",
      "\n",
      "0: 640x480 20 Chicks, 9.1ms\n",
      "Speed: 1.9ms preprocess, 9.1ms inference, 21.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 71  89  99  79  77  84  85  88 101  73  96 103 108 110 109 111]\n",
      "Processing frame 110\n",
      "\n",
      "0: 640x480 21 Chicks, 9.9ms\n",
      "Speed: 1.5ms preprocess, 9.9ms inference, 23.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [103  77 101  71  88 108  96  84  89  79  85  99 109 110 112 111]\n",
      "Processing frame 111\n",
      "\n",
      "0: 640x480 21 Chicks, 9.4ms\n",
      "Speed: 1.5ms preprocess, 9.4ms inference, 23.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [103  89  88  96  79  77  71  85  99  84 101 110 109 112 111]\n",
      "Processing frame 112\n",
      "\n",
      "0: 640x480 18 Chicks, 13.0ms\n",
      "Speed: 1.8ms preprocess, 13.0ms inference, 19.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [103  89 101  88  79  71  96  77  99  84  85 109 110 112 111]\n",
      "Processing frame 113\n",
      "\n",
      "0: 640x480 18 Chicks, 9.4ms\n",
      "Speed: 1.6ms preprocess, 9.4ms inference, 19.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 99  96  89  88 101 103  85  77  84  79 112 110 109 111]\n",
      "New Chick crossed the line! ID 84, Chicks in bounding box: 1, Total YOLO count: 22, Total BBV count: 22\n",
      "Processing frame 114\n",
      "\n",
      "0: 640x480 17 Chicks, 9.4ms\n",
      "Speed: 1.4ms preprocess, 9.4ms inference, 20.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 96  99 101  85  88  79  89  71  84 103  77 109]\n",
      "Processing frame 115\n",
      "\n",
      "0: 640x480 20 Chicks, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 20.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 96 101  85  88  89  84  77  79  71  99 110 109]\n",
      "Processing frame 116\n",
      "\n",
      "0: 640x480 19 Chicks, 9.5ms\n",
      "Speed: 1.5ms preprocess, 9.5ms inference, 19.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 96  89  85  77 101 108  84  94  88  99  71 111  79 110 109]\n",
      "New Chick crossed the line! ID 88, Chicks in bounding box: 1, Total YOLO count: 23, Total BBV count: 23\n",
      "Processing frame 117\n",
      "\n",
      "0: 640x480 21 Chicks, 9.6ms\n",
      "Speed: 1.8ms preprocess, 9.6ms inference, 22.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 96  85 101  88  94 108  89  84  71  99  79  77 109 110]\n",
      "Processing frame 118\n",
      "\n",
      "0: 640x480 20 Chicks, 9.0ms\n",
      "Speed: 1.5ms preprocess, 9.0ms inference, 59.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 96 108  99  88 101  94  85  84  89  79  77 115 109 110]\n",
      "Processing frame 119\n",
      "\n",
      "0: 640x480 23 Chicks, 9.3ms\n",
      "Speed: 1.4ms preprocess, 9.3ms inference, 23.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 96 108  85 101  88 111  84  94  89  99  79 109  71  77]\n",
      "Processing frame 120\n",
      "\n",
      "0: 640x480 19 Chicks, 9.5ms\n",
      "Speed: 1.8ms preprocess, 9.5ms inference, 20.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 96 108 101  94  88  84  85 111  79  99  89 109]\n",
      "New Chick crossed the line! ID 89, Chicks in bounding box: 1, Total YOLO count: 24, Total BBV count: 24\n",
      "Processing frame 121\n",
      "\n",
      "0: 640x480 16 Chicks, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 18.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [108 101  85 111  79  96  94  88  89  84  99 112 109]\n",
      "Processing frame 122\n",
      "\n",
      "0: 640x480 16 Chicks, 9.0ms\n",
      "Speed: 1.8ms preprocess, 9.0ms inference, 30.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [108  79 101  96  89  88  84 111  94  85  99 109 112 122]\n",
      "Processing frame 123\n",
      "\n",
      "0: 640x480 18 Chicks, 12.2ms\n",
      "Speed: 2.2ms preprocess, 12.2ms inference, 21.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [104  88  96 108  94  79  84  89 101 111  99 110 112  85 109]\n",
      "Processing frame 124\n",
      "\n",
      "0: 640x480 17 Chicks, 9.5ms\n",
      "Speed: 1.7ms preprocess, 9.5ms inference, 20.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [101 104  96 108 111  94  99  84  89  88  85 110 123  79 109 112]\n",
      "Processing frame 125\n",
      "\n",
      "0: 640x480 17 Chicks, 9.1ms\n",
      "Speed: 1.6ms preprocess, 9.1ms inference, 18.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 96 104 108  99 101  94  88  84 109 110  89  85 111 123 112  79]\n",
      "Processing frame 126\n",
      "\n",
      "0: 640x480 21 Chicks, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 23.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [108  96 104  88  99 101  94  89  84  85 109 123 112 110]\n",
      "Processing frame 127\n",
      "\n",
      "0: 640x480 21 Chicks, 8.9ms\n",
      "Speed: 1.5ms preprocess, 8.9ms inference, 21.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [104  96 123 108  85  89  84 109  88  94 101  99 110  79 112]\n",
      "Processing frame 128\n",
      "\n",
      "0: 640x480 20 Chicks, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 20.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [108 123  96  89 111  88 104 110  84 109  85  99 112  94 101  79 126 122 127]\n",
      "Processing frame 129\n",
      "\n",
      "0: 640x480 21 Chicks, 9.0ms\n",
      "Speed: 1.6ms preprocess, 9.0ms inference, 21.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [111 104  96 123 110  89  99  88 109 101  84 108  85 112  94 126 127 129 122]\n",
      "Processing frame 130\n",
      "\n",
      "0: 640x480 19 Chicks, 9.1ms\n",
      "Speed: 1.6ms preprocess, 9.1ms inference, 22.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [104  96 110 111 108 123  88 109  84  99  89  85  94 101 112 129 122]\n",
      "New Chick crossed the line! ID 96, Chicks in bounding box: 1, Total YOLO count: 25, Total BBV count: 25\n",
      "Processing frame 131\n",
      "\n",
      "0: 640x480 19 Chicks, 10.6ms\n",
      "Speed: 2.1ms preprocess, 10.6ms inference, 23.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 96 123 104  99 111 109  89  88 108 110  84 101  85  94 112 129 122]\n",
      "Processing frame 132\n",
      "\n",
      "0: 640x480 21 Chicks, 9.4ms\n",
      "Speed: 1.5ms preprocess, 9.4ms inference, 21.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 96 123  99 104 110 108 109 101  89  84  88  85  94 122 112]\n",
      "New Chick crossed the line! ID 94, Chicks in bounding box: 1, Total YOLO count: 26, Total BBV count: 26\n",
      "Processing frame 133\n",
      "\n",
      "0: 640x480 19 Chicks, 11.7ms\n",
      "Speed: 1.7ms preprocess, 11.7ms inference, 22.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [123 104 101  96 110  88 108  89  99 109  94  84 112  85 122]\n",
      "New Chick crossed the line! ID 101, Chicks in bounding box: 1, Total YOLO count: 27, Total BBV count: 27\n",
      "Processing frame 134\n",
      "\n",
      "0: 640x480 20 Chicks, 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 23.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 96  99 110 104  88 123  89 101 109 112  84  94 108 122]\n",
      "Processing frame 135\n",
      "\n",
      "0: 640x480 21 Chicks, 9.2ms\n",
      "Speed: 1.7ms preprocess, 9.2ms inference, 21.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [111 123  96 104 110 108  99 101  88  89  84 109 112  94 122]\n",
      "Processing frame 136\n",
      "\n",
      "0: 640x480 20 Chicks, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 21.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [111  96 108  88 110  89 104 109  99 123 101 112  84  94 122]\n",
      "Processing frame 137\n",
      "\n",
      "0: 640x480 18 Chicks, 25.0ms\n",
      "Speed: 1.8ms preprocess, 25.0ms inference, 44.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [110  96  88 123 111 104 109  99 101  94 108 112  89  84 122]\n",
      "Processing frame 138\n",
      "\n",
      "0: 640x480 18 Chicks, 12.8ms\n",
      "Speed: 1.5ms preprocess, 12.8ms inference, 25.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [110  88 111 104  96 108 109 101  99 123 112  94  84  89 122]\n",
      "Processing frame 139\n",
      "\n",
      "0: 640x480 18 Chicks, 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 20.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [110  88  96 111 101 104 108 109 112 123  99  89  94 122  84]\n",
      "New Chick crossed the line! ID 99, Chicks in bounding box: 1, Total YOLO count: 28, Total BBV count: 28\n",
      "Processing frame 140\n",
      "\n",
      "0: 640x480 20 Chicks, 10.2ms\n",
      "Speed: 2.0ms preprocess, 10.2ms inference, 33.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [110  88 104  96 101  99 112 111 123 109 108  94  89 122]\n",
      "Processing frame 141\n",
      "\n",
      "0: 640x480 19 Chicks, 9.8ms\n",
      "Speed: 1.5ms preprocess, 9.8ms inference, 22.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [110 101  89  96  88 123 112 104 111  99  94 109 108 122]\n",
      "New Chick crossed the line! ID 104, Chicks in bounding box: 1, Total YOLO count: 29, Total BBV count: 29\n",
      "Processing frame 142\n",
      "\n",
      "0: 640x480 19 Chicks, 9.8ms\n",
      "Speed: 1.6ms preprocess, 9.8ms inference, 24.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [104 111  96 110 101 123  99 108  89 112  88  94 109 122]\n",
      "New Chick crossed the line! ID 108, Chicks in bounding box: 1, Total YOLO count: 30, Total BBV count: 30\n",
      "Processing frame 143\n",
      "\n",
      "0: 640x480 20 Chicks, 9.1ms\n",
      "Speed: 1.9ms preprocess, 9.1ms inference, 21.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [104  96 101 110  89 111  99 123 108 112  94 109  88 122 134]\n",
      "Processing frame 144\n",
      "\n",
      "0: 640x480 20 Chicks, 10.5ms\n",
      "Speed: 1.6ms preprocess, 10.5ms inference, 37.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [110 101  96 104 111 112 123  89  99 108 109  88 134 122  94]\n",
      "Processing frame 145\n",
      "\n",
      "0: 640x480 19 Chicks, 9.5ms\n",
      "Speed: 1.8ms preprocess, 9.5ms inference, 22.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [101  99 104 110  96 123 112 111 109 108 122  89 134]\n",
      "Processing frame 146\n",
      "\n",
      "0: 640x480 18 Chicks, 9.4ms\n",
      "Speed: 1.5ms preprocess, 9.4ms inference, 20.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [101 104 110 123 129 112  99  96 111 108 109  94 122 134 136]\n",
      "Processing frame 147\n",
      "\n",
      "0: 640x480 17 Chicks, 24.3ms\n",
      "Speed: 1.8ms preprocess, 24.3ms inference, 44.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [129 104 111 123 110 101  96  99 112 108 109  94 134 122 136]\n",
      "Processing frame 148\n",
      "\n",
      "0: 640x480 20 Chicks, 10.3ms\n",
      "Speed: 1.5ms preprocess, 10.3ms inference, 25.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [ 99 104 111 129 123 110  96 101  94 112 109 108 134 136 122]\n",
      "Processing frame 149\n",
      "\n",
      "0: 640x480 18 Chicks, 9.7ms\n",
      "Speed: 1.6ms preprocess, 9.7ms inference, 29.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [123 126  99 104 111 129 110  96 101 112 108  94 109 136]\n",
      "Processing frame 150\n",
      "\n",
      "0: 640x480 18 Chicks, 10.8ms\n",
      "Speed: 1.8ms preprocess, 10.8ms inference, 42.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [126 129  99 123 104  96 111 112 101 110 108 109 136]\n",
      "Processing frame 151\n",
      "\n",
      "0: 640x480 16 Chicks, 9.5ms\n",
      "Speed: 2.3ms preprocess, 9.5ms inference, 25.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [104  99 126 129 111 123  96 108 110 112 101 109 139 136]\n",
      "New Chick crossed the line! ID 123, Chicks in bounding box: 1, Total YOLO count: 31, Total BBV count: 31\n",
      "New Chick crossed the line! ID 112, Chicks in bounding box: 1, Total YOLO count: 32, Total BBV count: 32\n",
      "Processing frame 152\n",
      "\n",
      "0: 640x480 16 Chicks, 9.0ms\n",
      "Speed: 1.4ms preprocess, 9.0ms inference, 20.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [104 127 111 126  96 123 108  99 110 129 101 112 109 136 139]\n",
      "Processing frame 153\n",
      "\n",
      "0: 640x480 16 Chicks, 10.7ms\n",
      "Speed: 1.6ms preprocess, 10.7ms inference, 37.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [123 101 126 111 127 129 110 112  99  96 108 109 104 139 136]\n",
      "Processing frame 154\n",
      "\n",
      "0: 640x480 18 Chicks, 9.2ms\n",
      "Speed: 1.9ms preprocess, 9.2ms inference, 24.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [127 123 101 111 126 110  99 109 108  96 129 104 139 112 140 136]\n",
      "Processing frame 155\n",
      "\n",
      "0: 640x480 18 Chicks, 10.4ms\n",
      "Speed: 2.3ms preprocess, 10.4ms inference, 31.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [127 101 111 110 123 129 126 109 112 108  99  96 140 104 139 136]\n",
      "New Chick crossed the line! ID 109, Chicks in bounding box: 1, Total YOLO count: 33, Total BBV count: 33\n",
      "Processing frame 156\n",
      "\n",
      "0: 640x480 16 Chicks, 9.8ms\n",
      "Speed: 1.8ms preprocess, 9.8ms inference, 23.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [123 111  99 110 129 127 108 109 101 126 104 112 140 139  96]\n",
      "Processing frame 157\n",
      "\n",
      "0: 640x480 19 Chicks, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 21.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [127 123 111 129 110  99 108 109 126 140 112 104 101 139 136]\n",
      "Processing frame 158\n",
      "\n",
      "0: 640x480 18 Chicks, 9.7ms\n",
      "Speed: 1.6ms preprocess, 9.7ms inference, 21.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [127 123 110 129 126  99 112 109 111 108 139 104 146 136]\n",
      "Processing frame 159\n",
      "\n",
      "0: 640x480 18 Chicks, 9.0ms\n",
      "Speed: 1.4ms preprocess, 9.0ms inference, 17.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [127 110 126 109  99 123 112 108 139 104 111 148 146 129 136]\n",
      "Processing frame 160\n",
      "\n",
      "0: 640x480 18 Chicks, 9.5ms\n",
      "Speed: 1.5ms preprocess, 9.5ms inference, 17.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [127  99 110 126 109 104 129 111 123 112 139 108 148 136]\n",
      "Processing frame 161\n",
      "\n",
      "0: 640x480 16 Chicks, 9.4ms\n",
      "Speed: 1.5ms preprocess, 9.4ms inference, 16.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [127 126 110 104  99 109 111 123 112 129 139 108 146 148]\n",
      "Processing frame 162\n",
      "\n",
      "0: 640x480 17 Chicks, 9.0ms\n",
      "Speed: 1.6ms preprocess, 9.0ms inference, 23.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [127 110  99 126 111 123 112 109 104 129 139 149 108 148 146]\n",
      "Processing frame 163\n",
      "\n",
      "0: 640x480 18 Chicks, 9.4ms\n",
      "Speed: 1.8ms preprocess, 9.4ms inference, 23.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [127 110 126 123 109 129 111  99 112 140 108 104 139 149 136 150 146 148]\n",
      "Processing frame 164\n",
      "\n",
      "0: 640x480 16 Chicks, 10.8ms\n",
      "Speed: 1.7ms preprocess, 10.8ms inference, 22.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [127 110 129 126 111 109 123 112 140 108 139 149  99 150 136]\n",
      "Processing frame 165\n",
      "\n",
      "0: 640x480 18 Chicks, 9.8ms\n",
      "Speed: 2.0ms preprocess, 9.8ms inference, 20.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [127 111 110 126 112 129 108 140 109 123 139 146 136]\n",
      "Processing frame 166\n",
      "\n",
      "0: 640x480 16 Chicks, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 25.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [127 126 129 111 110 140 112 123 109 108 139 146 136]\n",
      "New Chick crossed the line! ID 129, Chicks in bounding box: 1, Total YOLO count: 34, Total BBV count: 34\n",
      "Processing frame 167\n",
      "\n",
      "0: 640x480 15 Chicks, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 19.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [126 127 140 129 110 111 108 112 109 123 139 146 136]\n",
      "New Chick crossed the line! ID 110, Chicks in bounding box: 1, Total YOLO count: 35, Total BBV count: 35\n",
      "Processing frame 168\n",
      "\n",
      "0: 640x480 18 Chicks, 10.3ms\n",
      "Speed: 1.6ms preprocess, 10.3ms inference, 25.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [126 127 110 111 129 140 109 112 123 139 108 146 136]\n",
      "New Chick crossed the line! ID 126, Chicks in bounding box: 1, Total YOLO count: 36, Total BBV count: 36\n",
      "Processing frame 169\n",
      "\n",
      "0: 640x480 18 Chicks, 9.6ms\n",
      "Speed: 1.7ms preprocess, 9.6ms inference, 23.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [126 111 127 110 129 140 109 123 112 146 139 108 152 136]\n",
      "Processing frame 170\n",
      "\n",
      "0: 640x480 19 Chicks, 9.5ms\n",
      "Speed: 1.6ms preprocess, 9.5ms inference, 19.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [127 126 111 129 112 110 140 109 123 139 146 152]\n",
      "Processing frame 171\n",
      "\n",
      "0: 640x480 16 Chicks, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 17.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [126 127 129 110 111 140 112 123 109 146 139]\n",
      "Processing frame 172\n",
      "\n",
      "0: 640x480 18 Chicks, 9.0ms\n",
      "Speed: 1.6ms preprocess, 9.0ms inference, 17.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [126 129 111 110 112 140 123 127 109 139 159 160 158 146]\n",
      "Processing frame 173\n",
      "\n",
      "0: 640x480 20 Chicks, 9.5ms\n",
      "Speed: 1.5ms preprocess, 9.5ms inference, 20.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [111 129 126 127 140 110 123 112 139 109 160 146 159 158]\n",
      "New Chick crossed the line! ID 127, Chicks in bounding box: 1, Total YOLO count: 37, Total BBV count: 37\n",
      "Processing frame 174\n",
      "\n",
      "0: 640x480 21 Chicks, 11.6ms\n",
      "Speed: 1.8ms preprocess, 11.6ms inference, 24.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [129 111 127 126 110 140 112 123 146 164 160 139 159 109]\n",
      "Processing frame 175\n",
      "\n",
      "0: 640x480 20 Chicks, 9.7ms\n",
      "Speed: 1.6ms preprocess, 9.7ms inference, 23.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [129 127 111 126 140 112 110 160 164 139 123 146 165 109]\n",
      "Processing frame 176\n",
      "\n",
      "0: 640x480 21 Chicks, 9.8ms\n",
      "Speed: 1.5ms preprocess, 9.8ms inference, 22.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [129 112 111 110 127 140 126 164 146 160 139 165 159 109]\n",
      "Processing frame 177\n",
      "\n",
      "0: 640x480 22 Chicks, 9.1ms\n",
      "Speed: 1.4ms preprocess, 9.1ms inference, 21.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [112 111 126 140 129 110 127 164 109 139 146 160 170 165 169]\n",
      "New Chick crossed the line! ID 111, Chicks in bounding box: 1, Total YOLO count: 38, Total BBV count: 38\n",
      "Processing frame 178\n",
      "\n",
      "0: 640x480 23 Chicks, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 23.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [129 111 126 127 110 140 109 139 112 165 160 146 169 159 170]\n",
      "Processing frame 179\n",
      "\n",
      "0: 640x480 20 Chicks, 18.1ms\n",
      "Speed: 1.6ms preprocess, 18.1ms inference, 34.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [111 126 127 110 140 129 169 109 139 146 159 160 112]\n",
      "Processing frame 180\n",
      "\n",
      "0: 640x480 19 Chicks, 9.7ms\n",
      "Speed: 1.4ms preprocess, 9.7ms inference, 21.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [111 126 149 169 140 110 127 109 129 159 175 112 146]\n",
      "Processing frame 181\n",
      "\n",
      "0: 640x480 20 Chicks, 8.9ms\n",
      "Speed: 1.4ms preprocess, 8.9ms inference, 25.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [111 149 126 169 150 127 140 110 129 109 159 146]\n",
      "Processing frame 182\n",
      "\n",
      "0: 640x480 19 Chicks, 9.0ms\n",
      "Speed: 1.6ms preprocess, 9.0ms inference, 25.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [111 150 149 126 127 140 129 110 146 175 159 109]\n",
      "Processing frame 183\n",
      "\n",
      "0: 640x480 22 Chicks, 9.1ms\n",
      "Speed: 1.8ms preprocess, 9.1ms inference, 21.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [150 149 111 126 140 110 129 146 127 158 164 109 139 159 175 160]\n",
      "Processing frame 184\n",
      "\n",
      "0: 640x480 23 Chicks, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 22.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [149 150 111 140 127 126 129 146 164 159 160 158 110 139 175 181 182 109]\n",
      "Processing frame 185\n",
      "\n",
      "0: 640x480 20 Chicks, 10.0ms\n",
      "Speed: 1.9ms preprocess, 10.0ms inference, 23.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [149 129 111 150 126 127 140 164 110 158 160 184 139 146 159 182 181]\n",
      "Processing frame 186\n",
      "\n",
      "0: 640x480 22 Chicks, 9.8ms\n",
      "Speed: 1.7ms preprocess, 9.8ms inference, 25.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [150 129 111 149 140 126 127 158 159 164 110 139 160 184 182]\n",
      "Processing frame 187\n",
      "\n",
      "0: 640x480 23 Chicks, 14.2ms\n",
      "Speed: 2.0ms preprocess, 14.2ms inference, 24.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [150 140 111 126 149 164 129 127 158 159 146 185 182 139 160 184 110]\n",
      "Processing frame 188\n",
      "\n",
      "0: 640x480 23 Chicks, 9.2ms\n",
      "Speed: 2.0ms preprocess, 9.2ms inference, 24.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [150 111 149 140 126 127 164 159 158 187 185 184 146 188 182 160]\n",
      "Processing frame 189\n",
      "\n",
      "0: 640x480 23 Chicks, 9.2ms\n",
      "Speed: 1.7ms preprocess, 9.2ms inference, 27.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [150 126 169 111 159 127 140 149 164 158 187 184 146 185 188 139 182 189 181 160]\n",
      "New Chick crossed the line! ID 139, Chicks in bounding box: 1, Total YOLO count: 39, Total BBV count: 39\n",
      "Processing frame 190\n",
      "\n",
      "0: 640x480 20 Chicks, 9.4ms\n",
      "Speed: 1.9ms preprocess, 9.4ms inference, 26.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [150 169 111 140 164 149 127 126 159 139 158 184 191 146 182 160]\n",
      "New Chick crossed the line! ID 140, Chicks in bounding box: 1, Total YOLO count: 40, Total BBV count: 40\n",
      "New Chick crossed the line! ID 160, Chicks in bounding box: 1, Total YOLO count: 41, Total BBV count: 41\n",
      "Processing frame 191\n",
      "\n",
      "0: 640x480 21 Chicks, 10.5ms\n",
      "Speed: 1.7ms preprocess, 10.5ms inference, 36.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [150 111 140 169 139 127 126 164 159 149 158 184 189 181 160 146 191 182]\n",
      "Processing frame 192\n",
      "\n",
      "0: 640x480 21 Chicks, 12.3ms\n",
      "Speed: 2.3ms preprocess, 12.3ms inference, 32.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [150 169 140 111 127 189 126 164 149 159 139 158 184 146 191 181 160 182]\n",
      "Processing frame 193\n",
      "\n",
      "0: 640x480 21 Chicks, 12.0ms\n",
      "Speed: 2.3ms preprocess, 12.0ms inference, 24.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [150 169 126 111 140 164 149 139 189 127 159 158 184 181 160 146 182 191]\n",
      "New Chick crossed the line! ID 146, Chicks in bounding box: 1, Total YOLO count: 42, Total BBV count: 42\n",
      "Processing frame 194\n",
      "\n",
      "0: 640x480 22 Chicks, 9.8ms\n",
      "Speed: 1.4ms preprocess, 9.8ms inference, 26.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [169 150 139 126 140 165 111 127 149 189 159 181 158 164 184 146 160 182 148 191]\n",
      "New Chick crossed the line! ID 182, Chicks in bounding box: 1, Total YOLO count: 43, Total BBV count: 43\n",
      "Processing frame 195\n",
      "\n",
      "0: 640x480 20 Chicks, 9.5ms\n",
      "Speed: 2.1ms preprocess, 9.5ms inference, 49.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [169 150 111 126 165 181 164 127 149 140 159 139 184 158 146 189 160 182]\n",
      "Processing frame 196\n",
      "\n",
      "0: 640x480 21 Chicks, 9.6ms\n",
      "Speed: 1.9ms preprocess, 9.6ms inference, 31.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [150 169 181 165 140 192 127 139 111 149 164 159 158 184 126 146 160 189 182 191]\n",
      "Processing frame 197\n",
      "\n",
      "0: 640x480 23 Chicks, 11.2ms\n",
      "Speed: 1.8ms preprocess, 11.2ms inference, 51.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [169 181 150 140 192 165 139 111 149 158 159 164 184 127 160 126 146 182]\n",
      "Processing frame 198\n",
      "\n",
      "0: 640x480 22 Chicks, 8.9ms\n",
      "Speed: 1.5ms preprocess, 8.9ms inference, 26.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [192 169 165 140 150 111 181 149 139 159 158 164 184 146 160 127 182 126 191]\n",
      "Processing frame 199\n",
      "\n",
      "0: 640x480 22 Chicks, 9.3ms\n",
      "Speed: 1.4ms preprocess, 9.3ms inference, 22.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [169 181 150 165 140 149 192 111 139 159 158 164 184 160 146 182 195 127 191]\n",
      "Processing frame 200\n",
      "\n",
      "0: 640x480 20 Chicks, 9.0ms\n",
      "Speed: 1.7ms preprocess, 9.0ms inference, 33.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [192 181 169 111 165 140 159 150 164 149 139 158 184 191 146 160 195 182]\n",
      "Processing frame 201\n",
      "\n",
      "0: 640x480 20 Chicks, 9.3ms\n",
      "Speed: 1.4ms preprocess, 9.3ms inference, 20.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [181 192 169 165 111 150 140 159 164 158 149 139 191 160 184 146 195 197 182]\n",
      "New Chick crossed the line! ID 150, Chicks in bounding box: 1, Total YOLO count: 44, Total BBV count: 44\n",
      "Processing frame 202\n",
      "\n",
      "0: 640x480 20 Chicks, 9.5ms\n",
      "Speed: 1.5ms preprocess, 9.5ms inference, 21.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [181 165 192 150 169 140 159 139 111 164 160 158 149 184 146 191 195 197 182]\n",
      "Processing frame 203\n",
      "\n",
      "0: 640x480 21 Chicks, 8.8ms\n",
      "Speed: 1.6ms preprocess, 8.8ms inference, 21.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [181 165 192 164 169 140 150 111 158 159 139 149 191 184 160 146 182]\n",
      "Processing frame 204\n",
      "\n",
      "0: 640x480 21 Chicks, 9.2ms\n",
      "Speed: 1.4ms preprocess, 9.2ms inference, 21.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [181 111 140 165 169 150 164 192 159 158 149 191 184 139 160 146 198 182]\n",
      "Processing frame 205\n",
      "\n",
      "0: 640x480 22 Chicks, 9.3ms\n",
      "Speed: 1.4ms preprocess, 9.3ms inference, 21.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [181 169 192 165 150 159 111 139 164 140 160 158 198 149 184 191 146 182]\n",
      "New Chick crossed the line! ID 149, Chicks in bounding box: 1, Total YOLO count: 45, Total BBV count: 45\n",
      "Processing frame 206\n",
      "\n",
      "0: 640x480 21 Chicks, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 21.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [181 188 111 169 192 164 150 165 159 158 140 160 139 149 184 182 191]\n",
      "Processing frame 207\n",
      "\n",
      "0: 640x480 20 Chicks, 10.5ms\n",
      "Speed: 1.7ms preprocess, 10.5ms inference, 20.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [181 192 164 165 169 111 188 140 159 158 149 150 160 139 191 146 184]\n",
      "Processing frame 208\n",
      "\n",
      "0: 640x480 22 Chicks, 9.3ms\n",
      "Speed: 1.8ms preprocess, 9.3ms inference, 29.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [181 192 111 159 150 165 188 169 158 164 140 160 149 139 184 146 191 182]\n",
      "Processing frame 209\n",
      "\n",
      "0: 640x480 21 Chicks, 9.7ms\n",
      "Speed: 1.6ms preprocess, 9.7ms inference, 23.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [181 150 192 169 165 164 158 188 159 160 111 139 149 146 140 191 182 184]\n",
      "New Chick crossed the line! ID 164, Chicks in bounding box: 1, Total YOLO count: 46, Total BBV count: 46\n",
      "Processing frame 210\n",
      "\n",
      "0: 640x480 21 Chicks, 9.3ms\n",
      "Speed: 1.5ms preprocess, 9.3ms inference, 37.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [192 169 181 165 164 188 150 158 111 159 149 140 139 146 191 160 182]\n",
      "Processing frame 211\n",
      "\n",
      "0: 640x480 22 Chicks, 10.3ms\n",
      "Speed: 1.4ms preprocess, 10.3ms inference, 21.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [169 181 164 165 158 192 188 150 140 159 139 149 111 146 191 160 182]\n",
      "Processing frame 212\n",
      "\n",
      "0: 640x480 20 Chicks, 9.4ms\n",
      "Speed: 1.5ms preprocess, 9.4ms inference, 21.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [181 169 192 188 164 165 159 140 158 150 149 111 139 191 160 146 182]\n",
      "New Chick crossed the line! ID 169, Chicks in bounding box: 1, Total YOLO count: 47, Total BBV count: 47\n",
      "Processing frame 213\n",
      "\n",
      "0: 640x480 22 Chicks, 9.1ms\n",
      "Speed: 1.9ms preprocess, 9.1ms inference, 23.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [140 192 169 165 181 164 188 160 150 158 159 111 149 191 139 146 182]\n",
      "Processing frame 214\n",
      "\n",
      "0: 640x480 20 Chicks, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 23.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [181 169 165 192 164 140 158 188 159 149 146 160 191 150 111 139 201]\n",
      "New Chick crossed the line! ID 159, Chicks in bounding box: 1, Total YOLO count: 48, Total BBV count: 48\n",
      "Processing frame 215\n",
      "\n",
      "0: 640x480 24 Chicks, 9.5ms\n",
      "Speed: 1.7ms preprocess, 9.5ms inference, 24.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [181 164 169 188 192 165 140 158 159 202 149 191 150 160 201 182 146]\n",
      "New Chick crossed the line! ID 165, Chicks in bounding box: 1, Total YOLO count: 49, Total BBV count: 49\n",
      "Processing frame 216\n",
      "\n",
      "0: 640x480 20 Chicks, 9.1ms\n",
      "Speed: 1.7ms preprocess, 9.1ms inference, 22.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [169 192 164 181 165 159 188 202 158 140 149 146 150 191 203 201]\n",
      "New Chick crossed the line! ID 158, Chicks in bounding box: 1, Total YOLO count: 50, Total BBV count: 50\n",
      "Processing frame 217\n",
      "\n",
      "0: 640x480 20 Chicks, 9.5ms\n",
      "Speed: 1.8ms preprocess, 9.5ms inference, 32.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [192 181 169 165 164 158 188 159 202 191 150 140 149 146 201 203]\n",
      "Processing frame 218\n",
      "\n",
      "0: 640x480 19 Chicks, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 24.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [192 181 158 165 169 164 188 150 159 202 149 191 201 140 203 146]\n",
      "Processing frame 219\n",
      "\n",
      "0: 640x480 19 Chicks, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 21.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [181 165 192 169 164 158 159 202 188 150 203 149 191 207 140 201]\n",
      "Processing frame 220\n",
      "\n",
      "0: 640x480 18 Chicks, 9.4ms\n",
      "Speed: 1.7ms preprocess, 9.4ms inference, 19.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [192 164 165 181 169 158 188 202 150 159 203 201 191 207 149 140]\n",
      "Processing frame 221\n",
      "\n",
      "0: 640x480 17 Chicks, 9.3ms\n",
      "Speed: 1.6ms preprocess, 9.3ms inference, 17.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [169 192 181 158 165 164 150 202 188 159 201 203 207 191 140]\n",
      "Processing frame 222\n",
      "\n",
      "0: 640x480 17 Chicks, 10.9ms\n",
      "Speed: 1.9ms preprocess, 10.9ms inference, 20.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [181 197 192 158 164 169 150 188 202 159 165 201 203 149]\n",
      "Processing frame 223\n",
      "\n",
      "0: 640x480 18 Chicks, 9.5ms\n",
      "Speed: 1.4ms preprocess, 9.5ms inference, 21.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [197 181 192 169 164 158 165 202 150 188 195 159 201 203 149]\n",
      "Processing frame 224\n",
      "\n",
      "0: 640x480 18 Chicks, 9.0ms\n",
      "Speed: 1.8ms preprocess, 9.0ms inference, 23.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [197 192 165 181 202 158 164 188 195 169 159 203 150 201 149 208]\n",
      "New Chick crossed the line! ID 181, Chicks in bounding box: 1, Total YOLO count: 51, Total BBV count: 51\n",
      "Processing frame 225\n",
      "\n",
      "0: 640x480 17 Chicks, 12.0ms\n",
      "Speed: 1.8ms preprocess, 12.0ms inference, 34.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [197 181 192 202 164 165 159 169 188 158 195 203 201 149 208]\n",
      "Processing frame 226\n",
      "\n",
      "0: 640x480 19 Chicks, 9.3ms\n",
      "Speed: 1.5ms preprocess, 9.3ms inference, 21.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [197 181 192 165 169 195 188 159 202 158 164 208 149 203 201]\n",
      "Processing frame 227\n",
      "\n",
      "0: 640x480 16 Chicks, 10.5ms\n",
      "Speed: 1.5ms preprocess, 10.5ms inference, 22.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [197 181 192 165 202 169 158 188 195 159 164 201 149 203]\n",
      "Processing frame 228\n",
      "\n",
      "0: 640x480 17 Chicks, 9.5ms\n",
      "Speed: 2.1ms preprocess, 9.5ms inference, 20.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [197 192 181 169 165 195 158 159 164 202 188 203 149 201]\n",
      "New Chick crossed the line! ID 192, Chicks in bounding box: 1, Total YOLO count: 52, Total BBV count: 52\n",
      "Processing frame 229\n",
      "\n",
      "0: 640x480 17 Chicks, 9.0ms\n",
      "Speed: 1.9ms preprocess, 9.0ms inference, 18.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [181 197 192 169 165 164 159 203 158 202 195 188 201 149]\n",
      "New Chick crossed the line! ID 188, Chicks in bounding box: 1, Total YOLO count: 53, Total BBV count: 53\n",
      "Processing frame 230\n",
      "\n",
      "0: 640x480 16 Chicks, 9.9ms\n",
      "Speed: 1.4ms preprocess, 9.9ms inference, 23.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [181 192 197 164 203 169 165 159 195 158 202 188 201 149]\n",
      "Processing frame 231\n",
      "\n",
      "0: 640x480 18 Chicks, 9.1ms\n",
      "Speed: 1.8ms preprocess, 9.1ms inference, 34.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [192 181 165 197 169 158 202 195 203 159 164 201 188]\n",
      "Processing frame 232\n",
      "\n",
      "0: 640x480 17 Chicks, 9.5ms\n",
      "Speed: 1.6ms preprocess, 9.5ms inference, 18.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [169 165 197 192 181 195 158 159 201 202 203 164 188]\n",
      "Processing frame 233\n",
      "\n",
      "0: 640x480 16 Chicks, 9.1ms\n",
      "Speed: 2.2ms preprocess, 9.1ms inference, 30.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [169 165 197 192 181 188 201 159 158 202 203 195 212]\n",
      "Processing frame 234\n",
      "\n",
      "0: 640x480 16 Chicks, 8.9ms\n",
      "Speed: 1.5ms preprocess, 8.9ms inference, 21.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [169 197 181 195 159 192 165 201 188 158 202 213 203 212]\n",
      "Processing frame 235\n",
      "\n",
      "0: 640x480 16 Chicks, 12.3ms\n",
      "Speed: 2.0ms preprocess, 12.3ms inference, 24.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [165 181 197 159 202 192 188 213 158 195 201 169 203 212]\n",
      "Processing frame 236\n",
      "\n",
      "0: 640x480 16 Chicks, 12.3ms\n",
      "Speed: 2.3ms preprocess, 12.3ms inference, 20.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [197 181 207 159 202 192 195 165 201 188 158 213 203 215]\n",
      "Processing frame 237\n",
      "\n",
      "0: 640x480 17 Chicks, 10.2ms\n",
      "Speed: 2.6ms preprocess, 10.2ms inference, 40.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [197 207 195 159 181 192 188 213 202 201 158 203 165 215]\n",
      "Processing frame 238\n",
      "\n",
      "0: 640x480 19 Chicks, 9.3ms\n",
      "Speed: 1.7ms preprocess, 9.3ms inference, 27.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [207 197 188 181 192 195 201 202 158 213 203 159 217 215]\n",
      "New Chick crossed the line! ID 202, Chicks in bounding box: 1, Total YOLO count: 54, Total BBV count: 54\n",
      "Processing frame 239\n",
      "\n",
      "0: 640x480 19 Chicks, 10.2ms\n",
      "Speed: 1.7ms preprocess, 10.2ms inference, 28.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [207 197 181 188 192 202 195 201 213 203 217 158 218]\n",
      "New Chick crossed the line! ID 197, Chicks in bounding box: 1, Total YOLO count: 55, Total BBV count: 55\n",
      "Processing frame 240\n",
      "\n",
      "0: 640x480 15 Chicks, 8.9ms\n",
      "Speed: 1.7ms preprocess, 8.9ms inference, 22.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [181 197 207 192 202 188 195 201 213 217 203 218]\n",
      "Processing frame 241\n",
      "\n",
      "0: 640x480 15 Chicks, 9.7ms\n",
      "Speed: 2.0ms preprocess, 9.7ms inference, 33.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [197 181 192 195 201 207 202 188 213 203 217]\n",
      "Processing frame 242\n",
      "\n",
      "0: 640x480 15 Chicks, 9.2ms\n",
      "Speed: 2.8ms preprocess, 9.2ms inference, 16.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [197 192 207 188 201 181 202 195 213 217 203 223]\n",
      "Processing frame 243\n",
      "\n",
      "0: 640x480 15 Chicks, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 25.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [207 197 195 202 201 181 192 213 188 203 223 217 224]\n",
      "Processing frame 244\n",
      "\n",
      "0: 640x480 17 Chicks, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 36.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [207 195 197 201 202 192 181 188 213 203 223 217 224]\n",
      "Processing frame 245\n",
      "\n",
      "0: 640x480 17 Chicks, 9.2ms\n",
      "Speed: 2.5ms preprocess, 9.2ms inference, 26.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [207 192 195 197 181 201 202 213 188 224 223 217 203]\n",
      "New Chick crossed the line! ID 195, Chicks in bounding box: 1, Total YOLO count: 56, Total BBV count: 56\n",
      "Processing frame 246\n",
      "\n",
      "0: 640x480 17 Chicks, 8.9ms\n",
      "Speed: 1.7ms preprocess, 8.9ms inference, 21.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [207 197 192 195 202 181 201 213 224 217 223 203 188]\n",
      "Processing frame 247\n",
      "\n",
      "0: 640x480 17 Chicks, 9.8ms\n",
      "Speed: 2.3ms preprocess, 9.8ms inference, 21.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [207 192 197 181 201 202 213 228 224 195 217 188 203 223 227]\n",
      "Processing frame 248\n",
      "\n",
      "0: 640x480 20 Chicks, 9.6ms\n",
      "Speed: 1.7ms preprocess, 9.6ms inference, 26.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [197 207 181 192 202 201 213 188 195 228 217 227 223 203]\n",
      "New Chick crossed the line! ID 203, Chicks in bounding box: 1, Total YOLO count: 57, Total BBV count: 57\n",
      "Processing frame 249\n",
      "\n",
      "0: 640x480 19 Chicks, 9.5ms\n",
      "Speed: 1.9ms preprocess, 9.5ms inference, 29.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [207 181 192 197 213 188 202 228 201 217 195 223 229 203]\n",
      "Processing frame 250\n",
      "\n",
      "0: 640x480 19 Chicks, 9.6ms\n",
      "Speed: 1.6ms preprocess, 9.6ms inference, 22.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [192 197 207 181 213 188 195 201 202 228 203 217 223 229 230]\n",
      "Processing frame 251\n",
      "\n",
      "0: 640x480 19 Chicks, 9.0ms\n",
      "Speed: 1.7ms preprocess, 9.0ms inference, 20.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [213 207 197 181 201 195 202 228 192 188 217 203 223 229 230]\n",
      "New Chick crossed the line! ID 201, Chicks in bounding box: 1, Total YOLO count: 58, Total BBV count: 58\n",
      "Processing frame 252\n",
      "\n",
      "0: 640x480 20 Chicks, 9.0ms\n",
      "Speed: 2.2ms preprocess, 9.0ms inference, 22.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [181 212 207 197 213 195 201 228 230 229 217 202 203 223]\n",
      "Processing frame 253\n",
      "\n",
      "0: 640x480 20 Chicks, 9.8ms\n",
      "Speed: 1.4ms preprocess, 9.8ms inference, 19.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [212 197 181 207 213 195 201 228 217 202 203 231 223]\n",
      "Processing frame 254\n",
      "\n",
      "0: 640x480 18 Chicks, 9.1ms\n",
      "Speed: 1.6ms preprocess, 9.1ms inference, 19.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [213 207 181 212 197 224 195 201 228 202 217 203 231]\n",
      "Processing frame 255\n",
      "\n",
      "0: 640x480 19 Chicks, 11.5ms\n",
      "Speed: 2.1ms preprocess, 11.5ms inference, 49.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [213 195 212 207 197 201 202 181 224 228 217 203 223]\n",
      "Processing frame 256\n",
      "\n",
      "0: 640x480 18 Chicks, 11.2ms\n",
      "Speed: 5.3ms preprocess, 11.2ms inference, 22.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [212 213 197 195 207 201 224 228 202 203 217 233]\n",
      "Processing frame 257\n",
      "\n",
      "0: 640x480 18 Chicks, 9.6ms\n",
      "Speed: 1.8ms preprocess, 9.6ms inference, 29.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [207 197 213 228 212 195 201 203 217 202 224 233]\n",
      "Processing frame 258\n",
      "\n",
      "0: 640x480 19 Chicks, 16.6ms\n",
      "Speed: 2.4ms preprocess, 16.6ms inference, 19.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [207 197 195 212 201 213 203 228 217 224 202 233]\n",
      "Processing frame 259\n",
      "\n",
      "0: 640x480 19 Chicks, 10.0ms\n",
      "Speed: 1.9ms preprocess, 10.0ms inference, 20.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [197 207 195 228 213 212 201 203 202 224 217 233]\n",
      "New Chick crossed the line! ID 207, Chicks in bounding box: 1, Total YOLO count: 59, Total BBV count: 59\n",
      "Processing frame 260\n",
      "\n",
      "0: 640x480 18 Chicks, 10.8ms\n",
      "Speed: 1.7ms preprocess, 10.8ms inference, 23.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [202 215 228 212 213 195 207 197 201 224 203 217 236 233]\n",
      "Processing frame 261\n",
      "\n",
      "0: 640x480 18 Chicks, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 20.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [213 195 228 212 201 207 202 215 197 224 203 217 236 233]\n",
      "Processing frame 262\n",
      "\n",
      "0: 640x480 19 Chicks, 9.6ms\n",
      "Speed: 1.6ms preprocess, 9.6ms inference, 22.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [228 213 207 212 215 201 224 217 202 203 195 233 236]\n",
      "Processing frame 263\n",
      "\n",
      "0: 640x480 19 Chicks, 9.8ms\n",
      "Speed: 1.8ms preprocess, 9.8ms inference, 19.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [228 207 227 201 213 215 212 224 203 217 195 233]\n",
      "Processing frame 264\n",
      "\n",
      "0: 640x480 17 Chicks, 9.8ms\n",
      "Speed: 1.5ms preprocess, 9.8ms inference, 18.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [228 207 203 213 227 229 230 215 201 212 195 224 217 233]\n",
      "New Chick crossed the line! ID 213, Chicks in bounding box: 1, Total YOLO count: 60, Total BBV count: 60\n",
      "Processing frame 265\n",
      "\n",
      "0: 640x480 18 Chicks, 9.8ms\n",
      "Speed: 1.7ms preprocess, 9.8ms inference, 22.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [213 228 229 212 207 215 203 227 230 201 195 224 217 238 233]\n",
      "Processing frame 266\n",
      "\n",
      "0: 640x480 17 Chicks, 9.2ms\n",
      "Speed: 1.9ms preprocess, 9.2ms inference, 22.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [228 229 203 213 207 230 227 212 215 195 201 217 238 224 233]\n",
      "Processing frame 267\n",
      "\n",
      "0: 640x480 17 Chicks, 9.7ms\n",
      "Speed: 1.6ms preprocess, 9.7ms inference, 19.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [215 228 229 203 207 230 212 213 227 195 201 217 224 233]\n",
      "Processing frame 268\n",
      "\n",
      "0: 640x480 17 Chicks, 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 19.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [207 228 213 215 212 227 230 229 201 203 224 217 195]\n",
      "Processing frame 269\n",
      "\n",
      "0: 640x480 18 Chicks, 9.5ms\n",
      "Speed: 1.5ms preprocess, 9.5ms inference, 18.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [213 207 215 229 228 230 227 212 201 224 217 203 239 223 233]\n",
      "Processing frame 270\n",
      "\n",
      "0: 640x480 17 Chicks, 9.2ms\n",
      "Speed: 2.0ms preprocess, 9.2ms inference, 19.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [213 228 215 230 229 212 227 207 201 224 217 239 223]\n",
      "Processing frame 271\n",
      "\n",
      "0: 640x480 17 Chicks, 10.5ms\n",
      "Speed: 1.7ms preprocess, 10.5ms inference, 37.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [215 228 229 212 227 213 207 230 239 224 201 217 223]\n",
      "Processing frame 272\n",
      "\n",
      "0: 640x480 16 Chicks, 9.7ms\n",
      "Speed: 1.6ms preprocess, 9.7ms inference, 17.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [218 207 229 228 213 230 239 215 212 227 201 242 217 224 223]\n",
      "New Chick crossed the line! ID 212, Chicks in bounding box: 1, Total YOLO count: 61, Total BBV count: 61\n",
      "Processing frame 273\n",
      "\n",
      "0: 640x480 16 Chicks, 9.6ms\n",
      "Speed: 2.2ms preprocess, 9.6ms inference, 18.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [218 207 229 213 228 212 242 230 215 227 201 239 224 217 223]\n",
      "New Chick crossed the line! ID 217, Chicks in bounding box: 1, Total YOLO count: 62, Total BBV count: 62\n",
      "Processing frame 274\n",
      "\n",
      "0: 640x480 17 Chicks, 9.1ms\n",
      "Speed: 1.7ms preprocess, 9.1ms inference, 21.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [213 229 218 228 212 215 227 207 230 217 242 224 239 201 223]\n",
      "Processing frame 275\n",
      "\n",
      "0: 640x480 19 Chicks, 10.1ms\n",
      "Speed: 1.5ms preprocess, 10.1ms inference, 18.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [229 213 212 230 215 218 224 228 207 242 239 227 217 223]\n",
      "Processing frame 276\n",
      "\n",
      "0: 640x480 17 Chicks, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 19.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [229 207 230 215 228 212 213 227 218 239 242 224 217 223 243 233]\n",
      "New Chick crossed the line! ID 223, Chicks in bounding box: 1, Total YOLO count: 63, Total BBV count: 63\n",
      "New Chick crossed the line! ID 233, Chicks in bounding box: 1, Total YOLO count: 64, Total BBV count: 64\n",
      "Processing frame 277\n",
      "\n",
      "0: 640x480 20 Chicks, 9.1ms\n",
      "Speed: 1.8ms preprocess, 9.1ms inference, 28.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [229 212 218 228 215 227 213 230 207 224 242 217 223 243 239 233]\n",
      "Processing frame 278\n",
      "\n",
      "0: 640x480 19 Chicks, 20.3ms\n",
      "Speed: 1.6ms preprocess, 20.3ms inference, 20.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [229 215 212 218 207 228 230 227 213 239 224 217 223 243 242 233]\n",
      "Processing frame 279\n",
      "\n",
      "0: 640x480 18 Chicks, 9.3ms\n",
      "Speed: 1.5ms preprocess, 9.3ms inference, 19.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [212 229 213 215 218 230 228 207 239 227 224 217 247 242 223 233]\n",
      "Processing frame 280\n",
      "\n",
      "0: 640x480 18 Chicks, 11.7ms\n",
      "Speed: 1.7ms preprocess, 11.7ms inference, 30.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [212 229 215 213 218 228 230 207 224 239 227 217 223 247 242 233]\n",
      "Processing frame 281\n",
      "\n",
      "0: 640x480 18 Chicks, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 18.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [218 229 212 227 215 213 228 239 230 207 224 223 238 217 242 233]\n",
      "New Chick crossed the line! ID 215, Chicks in bounding box: 1, Total YOLO count: 65, Total BBV count: 65\n",
      "Processing frame 282\n",
      "\n",
      "0: 640x480 19 Chicks, 19.1ms\n",
      "Speed: 1.4ms preprocess, 19.1ms inference, 44.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [229 212 218 215 228 213 230 227 242 239 238 224 223 217 207 233]\n",
      "New Chick crossed the line! ID 224, Chicks in bounding box: 1, Total YOLO count: 66, Total BBV count: 66\n",
      "Processing frame 283\n",
      "\n",
      "0: 640x480 19 Chicks, 12.0ms\n",
      "Speed: 1.9ms preprocess, 12.0ms inference, 22.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [213 212 215 218 229 228 239 227 230 224 238 242 223 217 248]\n",
      "New Chick crossed the line! ID 227, Chicks in bounding box: 1, Total YOLO count: 67, Total BBV count: 67\n",
      "Processing frame 284\n",
      "\n",
      "0: 640x480 20 Chicks, 22.0ms\n",
      "Speed: 2.1ms preprocess, 22.0ms inference, 35.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [218 213 228 229 212 215 227 238 242 239 230 224 223 217 249 248 233]\n",
      "New Chick crossed the line! ID 228, Chicks in bounding box: 1, Total YOLO count: 68, Total BBV count: 68\n",
      "Processing frame 285\n",
      "\n",
      "0: 640x480 20 Chicks, 9.7ms\n",
      "Speed: 1.7ms preprocess, 9.7ms inference, 43.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [212 213 229 230 228 227 218 224 239 215 217 242 223 249 238]\n",
      "Processing frame 286\n",
      "\n",
      "0: 640x480 20 Chicks, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 22.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [229 228 213 218 212 224 230 239 227 215 242 217 249 223 238 250]\n",
      "New Chick crossed the line! ID 230, Chicks in bounding box: 1, Total YOLO count: 69, Total BBV count: 69\n",
      "Processing frame 287\n",
      "\n",
      "0: 640x480 20 Chicks, 9.2ms\n",
      "Speed: 2.0ms preprocess, 9.2ms inference, 22.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [229 212 213 218 228 224 215 227 239 230 242 238 217 249 223 250 233]\n",
      "New Chick crossed the line! ID 229, Chicks in bounding box: 1, Total YOLO count: 70, Total BBV count: 70\n",
      "Processing frame 288\n",
      "\n",
      "0: 640x480 23 Chicks, 10.0ms\n",
      "Speed: 1.9ms preprocess, 10.0ms inference, 24.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [212 213 229 224 218 228 239 227 215 230 217 242 223 233 250 249 238]\n",
      "Processing frame 289\n",
      "\n",
      "0: 640x480 19 Chicks, 9.7ms\n",
      "Speed: 1.5ms preprocess, 9.7ms inference, 22.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [218 212 229 227 238 224 230 213 228 239 215 242 217 250 233 223]\n",
      "Processing frame 290\n",
      "\n",
      "0: 640x480 18 Chicks, 9.8ms\n",
      "Speed: 1.4ms preprocess, 9.8ms inference, 23.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [212 229 243 238 213 224 215 227 228 218 230 242 239 217 223 250 233]\n",
      "Processing frame 291\n",
      "\n",
      "0: 640x480 18 Chicks, 9.8ms\n",
      "Speed: 1.5ms preprocess, 9.8ms inference, 19.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [242 229 254 224 243 227 218 215 228 213 238 239 230 212 217 250 233 223]\n",
      "Processing frame 292\n",
      "\n",
      "0: 640x480 20 Chicks, 10.8ms\n",
      "Speed: 1.7ms preprocess, 10.8ms inference, 26.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [254 242 212 229 218 243 228 224 239 238 227 215 230 213 250 217 233 223]\n",
      "Processing frame 293\n",
      "\n",
      "0: 640x480 24 Chicks, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 23.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [254 242 238 212 229 228 227 224 243 215 239 218 256 230 213 250 217 233 223]\n",
      "Processing frame 294\n",
      "\n",
      "0: 640x480 23 Chicks, 9.6ms\n",
      "Speed: 1.4ms preprocess, 9.6ms inference, 25.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [212 254 229 242 228 243 215 227 224 230 238 239 256 218 213 223 217 233]\n",
      "Processing frame 295\n",
      "\n",
      "0: 640x480 23 Chicks, 10.0ms\n",
      "Speed: 1.8ms preprocess, 10.0ms inference, 27.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [254 229 242 224 243 227 238 228 212 239 230 256 215 223 217 233 218 250]\n",
      "New Chick crossed the line! ID 218, Chicks in bounding box: 1, Total YOLO count: 71, Total BBV count: 71\n",
      "Processing frame 296\n",
      "\n",
      "0: 640x480 20 Chicks, 9.2ms\n",
      "Speed: 1.8ms preprocess, 9.2ms inference, 24.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [229 254 238 242 227 224 239 228 243 256 215 212 230 260 218 223 250]\n",
      "Processing frame 297\n",
      "\n",
      "0: 640x480 24 Chicks, 9.2ms\n",
      "Speed: 1.7ms preprocess, 9.2ms inference, 27.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [229 254 242 228 238 224 227 243 256 239 218 230 260 215 223 263 249 250 217]\n",
      "Processing frame 298\n",
      "\n",
      "0: 640x480 23 Chicks, 9.2ms\n",
      "Speed: 1.5ms preprocess, 9.2ms inference, 26.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Tracker IDs this frame: [229 224 242 254 227 238 243 215 239 228 260 256 230 249 218 263 223 217]\n",
      "New Chick crossed the line! ID 239, Chicks in bounding box: 1, Total YOLO count: 72, Total BBV count: 72\n",
      "Processing frame 299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_line_from_video_frame(frame):\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    # Draw a horizontal line across the middle of the frame\n",
    "    line_start = (frame_width, frame_height // 2)\n",
    "    line_end = (0, frame_height // 2)\n",
    "    return [line_start, line_end]\n",
    "\n",
    "def chick_counting(video_path, output_path, line_points, verbose = False):\n",
    "\n",
    "    # Grab a sample frame so we know video size\n",
    "    generator = sv.get_video_frames_generator(video_path)\n",
    "    frame = next(generator)\n",
    "\n",
    "    # Set up video writer with same FPS/size as input\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame.shape[1], frame.shape[0]))\n",
    "    if not out.isOpened():\n",
    "        print(\"Error: Could not open video writer\")\n",
    "        return\n",
    "\n",
    "    # Init tracker and helpers\n",
    "    byte_tracker = sv.ByteTrack()\n",
    "    trace_annotator = sv.TraceAnnotator(thickness=4, trace_length=50)\n",
    "\n",
    "    # Create the counting line\n",
    "    line_zone = sv.LineZone(start=sv.Point(*line_points[0]), end=sv.Point(*line_points[1]))\n",
    "\n",
    "    # Load custom YOLO model\n",
    "    model = YOLO_MODEL\n",
    "    \n",
    "    # Annotators for boxes + labels\n",
    "    BOUNDING_BOX_ANNOTATOR = sv.BoxAnnotator(thickness=2, color=sv.Color(0, 255, 0))\n",
    "    LABEL_ANNOTATOR = sv.LabelAnnotator(text_scale=1)\n",
    "\n",
    "    # Counters\n",
    "    frame_count = 0\n",
    "    total_count = 0\n",
    "    total_count_bbv = 0\n",
    "    all_counted_ids = set()  # keep track of already-counted trackers\n",
    "    all_counted_ids_bbv = set()  # Seperate list for the bounding box validation\n",
    "    \n",
    "    # Constants to hold high and low thermal temperatures for denormalization\n",
    "    prev_hi = None\n",
    "    prev_lo = None\n",
    "\n",
    "    try:\n",
    "        generator = sv.get_video_frames_generator(video_path)\n",
    "\n",
    "        for frame in generator:\n",
    "            frame_count += 1\n",
    "            if verbose:\n",
    "                print(f\"Processing frame {frame_count}\")\n",
    "\n",
    "            # Run YOLO on frame\n",
    "            results = model(frame)[0]\n",
    "            \n",
    "            # Get the frame image as denormalized numpy array\n",
    "            try:\n",
    "                temp_arr, prev_hi, prev_lo = result_to_temp_frame(\n",
    "                    results,\n",
    "                    frame_idx = frame_count,\n",
    "                    prev_hi_val = prev_hi,\n",
    "                    prev_lo_val = prev_lo\n",
    "                )\n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"Warning: Could not convert frame {frame_count} to temperature array. Skipping BBV for this frame.\")\n",
    "                if prev_hi is not None and prev_lo is not None:\n",
    "                    temp_arr = np.zeros_like(frame[..., 0], dtype=np.float32)  # reuse last temp_arr shape\n",
    "                else:\n",
    "                    temp_arr = None\n",
    "\n",
    "            # Convert results to supervision Detections\n",
    "            detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "            # Sensitivity for declaring a box as \"nested\" (e.g. 0.9 means inner must have at least 90% of its area inside outer)\n",
    "            NESTED_THRESHOLD = 0.9  \n",
    "\n",
    "            # Get indicies of all boxes\n",
    "            contained_indices = set()\n",
    "            boxes = detections.xyxy\n",
    "\n",
    "            for i, outer in enumerate(boxes):\n",
    "                x1o, y1o, x2o, y2o = outer\n",
    "                outer_area = max(0, (x2o - x1o)) * max(0, (y2o - y1o))\n",
    "\n",
    "                for j, inner in enumerate(boxes):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    x1i, y1i, x2i, y2i = inner\n",
    "                    inner_area = max(0, (x2i - x1i)) * max(0, (y2i - y1i))\n",
    "\n",
    "                    # Intersection box\n",
    "                    inter_x1 = max(x1o, x1i)\n",
    "                    inter_y1 = max(y1o, y1i)\n",
    "                    inter_x2 = min(x2o, x2i)\n",
    "                    inter_y2 = min(y2o, y2i)\n",
    "\n",
    "                    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
    "\n",
    "                    # Ratio of inner covered by outer\n",
    "                    if inner_area > 0 and (inter_area / inner_area) >= NESTED_THRESHOLD:\n",
    "                        contained_indices.add(j)\n",
    "\n",
    "\n",
    "            # Update tracker with detections\n",
    "            detections = byte_tracker.update_with_detections(detections)\n",
    "            if verbose:\n",
    "                print(\"Tracker IDs this frame:\", detections.tracker_id)\n",
    "\n",
    "            # See if any trackers crossed the line\n",
    "            crossed_in_flags, crossed_out_flags = line_zone.trigger(detections)\n",
    "\n",
    "            # Only count new IDs that cross \"in\"\n",
    "            for i, crossed in enumerate(crossed_in_flags):\n",
    "                if crossed:\n",
    "                    tracker_id = detections.tracker_id[i]\n",
    "                    \n",
    "                    if tracker_id is None: continue  # Skip if no tracker ID\n",
    "                    \n",
    "                    # Track bounding boxes\n",
    "                    if tracker_id not in all_counted_ids:\n",
    "                        # Add to the YOLO total count\n",
    "                        total_count += 1\n",
    "                        all_counted_ids.add(tracker_id)\n",
    "                        \n",
    "                        # Run the BBV on this bouning box\n",
    "                        cur_box_count = get_box_count(\n",
    "                            pipeline=BBV_PIPELINE_NO_GROUPING,\n",
    "                            temperature_frame=temp_arr,\n",
    "                            box=detections.xyxy[i]\n",
    "                        )\n",
    "                        total_count_bbv += cur_box_count\n",
    "                        \n",
    "                        if verbose:\n",
    "                            print(f\"New Chick crossed the line! ID {tracker_id}, Chicks in bounding box: {cur_box_count}, Total YOLO count: {total_count}, Total BBV count: {total_count_bbv}\")\n",
    "\n",
    "            # Assign labels + colors depending on nesting\n",
    "            labels = []\n",
    "            colors = []\n",
    "            for i, tracker_id in enumerate(detections.tracker_id):\n",
    "                if i in contained_indices:\n",
    "                    labels.append(f\"#{tracker_id} nested\")\n",
    "                    colors.append(sv.Color.RED)\n",
    "                else:\n",
    "                    labels.append(f\"#{tracker_id} chick\")\n",
    "                    colors.append(sv.Color.GREEN)\n",
    "\n",
    "            # Draw tracker trails\n",
    "            annotated_frame = trace_annotator.annotate(scene=frame.copy(), detections=detections)\n",
    "\n",
    "            # Draw bounding boxes manually with chosen colors\n",
    "            for i, box in enumerate(detections.xyxy):\n",
    "                color = colors[i] if i < len(colors) else sv.Color.GREEN\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color.as_bgr(), 2)\n",
    "\n",
    "            # Draw labels\n",
    "            # Draw smaller labels with smaller background rectangles\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.4  # significantly smaller\n",
    "            thickness = 1\n",
    "            pad = 3\n",
    "\n",
    "            for i, lbl in enumerate(labels):\n",
    "                x1, y1, x2, y2 = map(int, detections.xyxy[i])\n",
    "                text_size, _ = cv2.getTextSize(lbl, font, font_scale, thickness)\n",
    "                text_w, text_h = text_size\n",
    "\n",
    "                # Position label above box if space, otherwise below\n",
    "                if y1 - text_h - 2 * pad > 0:\n",
    "                    rect_tl = (x1, y1 - text_h - 2 * pad)\n",
    "                    rect_br = (x1 + text_w + 2 * pad, y1)\n",
    "                    text_org = (x1 + pad, y1 - pad)\n",
    "                else:\n",
    "                    rect_tl = (x1, y1)\n",
    "                    rect_br = (x1 + text_w + 2 * pad, y1 + text_h + 2 * pad)\n",
    "                    text_org = (x1 + pad, y1 + text_h + pad)\n",
    "\n",
    "                # Background color: use tracker color if available, else black\n",
    "                bg_color = colors[i].as_bgr() if i < len(colors) else (0, 0, 0)\n",
    "                # Choose text color for contrast\n",
    "                text_color = (0, 0, 0) if sum(bg_color) > 382 else (255, 255, 255)\n",
    "\n",
    "                cv2.rectangle(annotated_frame, rect_tl, rect_br, bg_color, cv2.FILLED)\n",
    "                cv2.putText(annotated_frame, lbl, text_org, font, font_scale, text_color, thickness, cv2.LINE_AA)\n",
    "\n",
    "            # Draw the counting line\n",
    "            cv2.line(annotated_frame, line_points[0], line_points[1], (0, 0, 255), 2)\n",
    "\n",
    "            # Overlay YOLO total count\n",
    "            cv2.putText(\n",
    "                annotated_frame,\n",
    "                f'Total Count: {total_count}',\n",
    "                (10, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 255, 0),\n",
    "                2,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "            # Overlay BBV total count\n",
    "            cv2.putText(\n",
    "                annotated_frame,\n",
    "                f'BBV Total Count: {total_count_bbv}',\n",
    "                (10, 80),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (255, 0, 0),\n",
    "                2,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "            # Overlay True total count\n",
    "            cv2.putText(\n",
    "                annotated_frame,\n",
    "                f'True Total Count: {TRUE_COUNT}',\n",
    "                (10, 110),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 0, 255),\n",
    "                2,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "\n",
    "            # Write out annotated frame\n",
    "            out.write(annotated_frame)\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Detailed exception logging\n",
    "        print(\"=== Exception while processing video frames ===\")\n",
    "        print(\"Time:\", datetime.datetime.now().isoformat())\n",
    "        print(\"Exception type:\", type(e).__name__)\n",
    "        print(\"Exception message:\", str(e))\n",
    "        print(\"Full traceback:\")\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "    finally:\n",
    "        # Clean up writer and windows\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(f\"Total Frames Processed: {frame_count}\\nYOLO Count = {total_count}, BBV Total = {total_count_bbv}, True Count = {TRUE_COUNT}\")\n",
    "        if verbose:\n",
    "            print(f\"LineZone internal count (for reference): in={line_zone.in_count}, out={line_zone.out_count}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import tkinter as tk\n",
    "    from tkinter.filedialog import askopenfilename, askdirectory\n",
    "    tk.Tk().withdraw()\n",
    "\n",
    "    # Pick input video + output folder with file dialogs\n",
    "    SOURCE_VIDEO_PATH = askopenfilename()\n",
    "    print(\"User chose:\", SOURCE_VIDEO_PATH)\n",
    "\n",
    "    folder_path = askdirectory()\n",
    "    print(\"Output folder:\", folder_path)\n",
    "\n",
    "    # Build output filename\n",
    "    filename_no_ext = SOURCE_VIDEO_PATH.split('/')[-1].rsplit('.', 1)[0]\n",
    "    OUTPUT_PATH = f\"{folder_path}/{filename_no_ext}-outputfile(colored).mp4\"\n",
    "    print(\"Output path:\", OUTPUT_PATH)\n",
    "\n",
    "    # Grab a frame to define the line\n",
    "    cap = cv2.VideoCapture(SOURCE_VIDEO_PATH)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read the video\")\n",
    "        exit()\n",
    "    cap.release()\n",
    "\n",
    "    line_points = get_line_from_video_frame(frame)\n",
    "    print(\"Line points:\", line_points)\n",
    "\n",
    "    # Only run if line points are valid\n",
    "    if len(line_points) == 2:\n",
    "        chick_counting(SOURCE_VIDEO_PATH, OUTPUT_PATH, line_points, verbose=True)\n",
    "    else:\n",
    "        print(\"Error: Not enough points to define the counting line.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
