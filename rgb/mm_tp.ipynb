{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00d8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from ultralytics import solutions\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(\"legacy/proof_of_concept/demo_data/deer.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "# Get video properties: width, height, and frames per second (fps)\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define points for a line or region of interest in the video frame\n",
    "line_points = [(400, 100), (400, 620)]  # Line coordinates\n",
    "\n",
    "# Initialize the video writer to save the output video\n",
    "video_writer = cv2.VideoWriter(\"object_counting_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "model = \"models/yolo11n.pt\"\n",
    "\n",
    "# Initialize the Object Counter with visualization options and other parameters\n",
    "counter = solutions.ObjectCounter(\n",
    "    show=True,  \t\t\t\t\t\t\t# Display the image during processing\n",
    "    region=line_points,  \t\t\t\t\t# Region of interest points\n",
    "    model=\"models/best.pt\",  \t\t\t# Ultralytics YOLO11 model file\n",
    "    line_width=2,  \t\t\t\t\t\t\t# Thickness of the lines and bounding boxes\n",
    ")\n",
    "\n",
    "# Process video frames in a loop\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
    "    # Use the Object Counter to count objects in the frame and get the annotated image\n",
    "    im0 = counter.count(im0)\n",
    "\n",
    "    # Write the annotated frame to the output video\n",
    "    video_writer.write(im0)\n",
    "\n",
    "# Release the video capture and writer objects\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c9ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO  # pip install ultralytics\n",
    "\n",
    "# =========================================\n",
    "# 1) Geometry helpers: crossing detection\n",
    "# =========================================\n",
    "def orient(a, b, c):\n",
    "    # 2D cross product (b-a) x (c-a)\n",
    "    return (b[0]-a[0])*(c[1]-a[1]) - (b[1]-a[1])*(c[0]-a[0])\n",
    "\n",
    "def segments_intersect(p1, p2, q1, q2):\n",
    "    # Proper segment intersection (including touching)\n",
    "    o1 = orient(p1, p2, q1)\n",
    "    o2 = orient(p1, p2, q2)\n",
    "    o3 = orient(q1, q2, p1)\n",
    "    o4 = orient(q1, q2, p2)\n",
    "    if (o1 == 0 and o2 == 0 and o3 == 0 and o4 == 0):\n",
    "        # collinear: check bbox overlap\n",
    "        return (min(p1[0], p2[0]) <= max(q1[0], q2[0]) and\n",
    "                min(q1[0], q2[0]) <= max(p1[0], p2[0]) and\n",
    "                min(p1[1], p2[1]) <= max(q1[1], q2[1]) and\n",
    "                min(q1[1], q2[1]) <= max(p1[1], p2[1]))\n",
    "    return (o1 == 0 or o2 == 0 or np.sign(o1) != np.sign(o2)) and \\\n",
    "           (o3 == 0 or o4 == 0 or np.sign(o3) != np.sign(o4))\n",
    "\n",
    "def line_side(p, a, b):\n",
    "    # +1 if p is to the left of a->b, -1 if right, 0 on the line\n",
    "    s = orient(a, b, p)\n",
    "    return 0 if s == 0 else (1 if s > 0 else -1)\n",
    "\n",
    "# =========================================\n",
    "# 2) Feature extraction stub (you customize)\n",
    "# =========================================\n",
    "def get_features(roi_bgr: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Return a scalar feature X for the bbox image patch.\n",
    "    Replace with YOUR features (color/texture CNN embedding, HOG, etc.)\n",
    "    \"\"\"\n",
    "    if roi_bgr.size == 0:\n",
    "        return 0.0\n",
    "    gray = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    mean_intensity = float(gray.mean())\n",
    "    h, w = gray.shape[:2]\n",
    "    area_norm = (h * w) / 1e4  # rough normalization\n",
    "    return mean_intensity * np.log1p(area_norm)\n",
    "\n",
    "# =======================================================\n",
    "# 3) Tiny model: non-negative outputs via exp(w*x + b)\n",
    "#    Optimized on grouped interval-sum squared loss\n",
    "# =======================================================\n",
    "class GroupedExpSGD:\n",
    "    def __init__(self, lr=1e-3, epochs=300, l2=1e-6):\n",
    "        self.w = 0.0\n",
    "        self.b = 0.0\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.l2 = l2\n",
    "\n",
    "    def fit(self, X_events, intervals_event_ranges, dY):\n",
    "        \"\"\"\n",
    "        X_events: (N_events,) scalar features for each crossing event, in time order\n",
    "        intervals_event_ranges: list of (start_idx, end_idx) INCLUSIVE for event indices\n",
    "                                covering each labeled interval in order\n",
    "        dY: (K,) ground-truth increments for those intervals\n",
    "        \"\"\"\n",
    "        X = np.asarray(X_events, float)\n",
    "        K = len(intervals_event_ranges)\n",
    "        assert K == len(dY)\n",
    "        for _ in range(self.epochs):\n",
    "            grad_w = self.l2 * self.w\n",
    "            grad_b = self.l2 * self.b\n",
    "            for k, (a, b) in enumerate(intervals_event_ranges):\n",
    "                if a > b:  # no events in this interval\n",
    "                    # Can't fit; leave residual for diagnostics\n",
    "                    continue\n",
    "                xk = X[a:b+1]\n",
    "                rk = np.exp(self.w * xk + self.b)   # event outputs (>=0)\n",
    "                yhat = rk.sum()\n",
    "                err = (yhat - dY[k])                # dL/dyhat = err\n",
    "                grad_w += err * np.sum(rk * xk)     # chain rule\n",
    "                grad_b += err * np.sum(rk)\n",
    "            # Gradient step\n",
    "            self.w -= self.lr * grad_w\n",
    "            self.b -= self.lr * grad_b\n",
    "        return self\n",
    "\n",
    "    def predict_events(self, X_events):\n",
    "        X = np.asarray(X_events, float)\n",
    "        return np.exp(self.w * X + self.b)          # >= 0\n",
    "\n",
    "# =========================================\n",
    "# 4) Main: run tracking, collect events\n",
    "# =========================================\n",
    "def run_and_train(\n",
    "    video_path=\"legacy/proof_of_concept/demo_data/deer.mp4\",\n",
    "    model_path=\"models/best.pt\",\n",
    "    csv_path=\"../.local_data/counts_xy_true_vs_yolo_series.csv\",          # must contain: frame_idx, cum_count (optionally true_count)\n",
    "    out_path=\"object_counting_output.avi\",\n",
    "    line_points=[(320, 560), (1820, 540)],\n",
    "    draw=True\n",
    "):\n",
    "    # Read labels\n",
    "    labels = pd.read_csv(csv_path)\n",
    "    if \"frame_index\" not in labels or \"true_count\" not in labels:\n",
    "        raise ValueError(\"CSV must have columns: frame_index, true_count (optionally true_count).\")\n",
    "    labels = labels.sort_values(\"frame_index\").reset_index(drop=True)\n",
    "\n",
    "    # Build label checkpoints and increments\n",
    "    L_frames = labels[\"frame_index\"].to_numpy().astype(int)\n",
    "    cum = labels[\"true_count\"].to_numpy().astype(float)\n",
    "    # Prefer increments from cum to be robust; fallback to provided true_count if you like\n",
    "    dY = np.diff(np.concatenate([[0.0], cum]))     # length K == number of checkpoints\n",
    "\n",
    "    # Video IO\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    assert cap.isOpened(), \"Error reading video file\"\n",
    "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    vw = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "    # Line setup\n",
    "    A = tuple(map(int, line_points[0]))\n",
    "    B = tuple(map(int, line_points[1]))\n",
    "\n",
    "    # YOLO tracker\n",
    "    yolo = YOLO(model_path)\n",
    "\n",
    "    # Tracking memory: last center per track id\n",
    "    last_center = {}   # id -> (x,y)\n",
    "\n",
    "    # Collected events\n",
    "    event_frames = []  # frame_idx for each crossing event\n",
    "    event_X = []       # scalar feature X per event\n",
    "\n",
    "    f_idx = -1\n",
    "    label_ptr = 0  # for overlaying cum truth if desired\n",
    "    cum_pred_running = 0.0  # overlay of cumulative predicted events (optional)\n",
    "\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        f_idx += 1\n",
    "\n",
    "        # Run tracking on the current frame\n",
    "        results = yolo.track(frame, persist=True, verbose=False)\n",
    "        r = results[0]  # ultralytics Results\n",
    "        boxes = getattr(r, \"boxes\", None)\n",
    "        if boxes is not None and boxes.id is not None:\n",
    "            ids = boxes.id.cpu().numpy().astype(int)\n",
    "            xyxy = boxes.xyxy.cpu().numpy()  # (N,4)\n",
    "            for tid, bb in zip(ids, xyxy):\n",
    "                x1, y1, x2, y2 = bb.astype(int)\n",
    "                cx = (x1 + x2) // 2\n",
    "                cy = (y1 + y2) // 2\n",
    "                curr = (int(cx), int(cy))\n",
    "                prev = last_center.get(tid, None)\n",
    "\n",
    "                # crossing test (center trajectory vs counting line)\n",
    "                if prev is not None:\n",
    "                    if segments_intersect(prev, curr, A, B) and (line_side(prev, A, B) * line_side(curr, A, B) <= 0):\n",
    "                        # Crop ROI for features\n",
    "                        xx1, yy1 = max(0, x1), max(0, y1)\n",
    "                        xx2, yy2 = min(w, x2), min(h, y2)\n",
    "                        roi = frame[yy1:yy2, xx1:xx2]\n",
    "                        X = get_features(roi)\n",
    "                        event_frames.append(f_idx)\n",
    "                        event_X.append(float(X))\n",
    "\n",
    "                        # (Optional) draw a flash on crossing\n",
    "                        if draw:\n",
    "                            cv2.circle(frame, curr, 8, (0, 255, 0), -1)\n",
    "                last_center[tid] = curr\n",
    "\n",
    "        # Draw line and current stats\n",
    "        if draw:\n",
    "            cv2.line(frame, A, B, (0, 0, 255), 2)\n",
    "\n",
    "        vw.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    vw.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # ============================\n",
    "    # Build intervals over EVENTS\n",
    "    # ============================\n",
    "    # Sort events by time (already in order because we appended by frame)\n",
    "    event_frames = np.asarray(event_frames, int)\n",
    "    event_X = np.asarray(event_X, float)\n",
    "    N_events = len(event_X)\n",
    "\n",
    "    # Map label checkpoints to contiguous event index ranges\n",
    "    # For checkpoint k at frame L_frames[k], interval k is (prev_label_frame, current_label_frame]\n",
    "    intervals = []\n",
    "    start_event_idx = 0\n",
    "    prev_f = -1\n",
    "    for k, f_lab in enumerate(L_frames):\n",
    "        # events with prev_f < frame_idx <= f_lab belong to this interval\n",
    "        end_event_idx = start_event_idx - 1\n",
    "        while end_event_idx + 1 < N_events and event_frames[end_event_idx + 1] <= f_lab:\n",
    "            end_event_idx += 1\n",
    "        intervals.append((start_event_idx, max(start_event_idx - 1, end_event_idx)))  # (a,b) inclusive; empty if a>b\n",
    "        start_event_idx = end_event_idx + 1\n",
    "        prev_f = f_lab\n",
    "\n",
    "    # ============================\n",
    "    # Train on grouped intervals\n",
    "    # ============================\n",
    "    model = GroupedExpSGD(lr=3e-3, epochs=400, l2=1e-6).fit(event_X, intervals, dY)\n",
    "\n",
    "    # ============================\n",
    "    # Evaluation (weak supervision)\n",
    "    # ============================\n",
    "    # 1) Interval-level error (how well we match increments)\n",
    "    yhat_events = model.predict_events(event_X)  # per-event non-negative outputs\n",
    "    inc_preds = []\n",
    "    for a, b in intervals:\n",
    "        inc_preds.append(0.0 if a > b else float(yhat_events[a:b+1].sum()))\n",
    "    inc_preds = np.asarray(inc_preds)\n",
    "    inc_true = dY\n",
    "\n",
    "    # 2) Cumulative at checkpoints\n",
    "    cum_pred = np.cumsum(inc_preds)\n",
    "    cum_true = cum\n",
    "\n",
    "    # Metrics\n",
    "    def rmse(x, y): return float(np.sqrt(np.mean((np.asarray(x) - np.asarray(y))**2)))\n",
    "    def mae(x, y):  return float(np.mean(np.abs(np.asarray(x) - np.asarray(y))))\n",
    "\n",
    "    metrics = {\n",
    "        \"interval_RMSE\": rmse(inc_preds, inc_true),\n",
    "        \"interval_MAE\":  mae(inc_preds, inc_true),\n",
    "        \"cumulative_RMSE\": rmse(cum_pred, cum_true),\n",
    "        \"cumulative_MAE\":  mae(cum_pred, cum_true),\n",
    "        \"events_total\": int(N_events),\n",
    "        \"intervals\": len(intervals),\n",
    "        \"empty_intervals_with_positive_truth\":\n",
    "            int(sum(1 for (a,b),dy in zip(intervals, dY) if a > b and dy > 0))\n",
    "    }\n",
    "\n",
    "    print(\"=== Weak-supervision evaluation ===\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k:>34}: {v}\")\n",
    "\n",
    "    # Example: get per-checkpoint details\n",
    "    report = pd.DataFrame({\n",
    "        \"frame_idx\": L_frames,\n",
    "        \"inc_true\": inc_true,\n",
    "        \"inc_pred\": inc_preds,\n",
    "        \"cum_true\": cum_true,\n",
    "        \"cum_pred\": cum_pred\n",
    "    })\n",
    "    print(\"\\nCheckpoint report (head):\\n\", report.head())\n",
    "\n",
    "    return model, (event_frames, event_X), report, metrics\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Edit paths as needed; CSV columns required: frame_idx, cum_count (optionally true_count)\n",
    "    run_and_train(\n",
    "        video_path=\"legacy/proof_of_concept/demo_data/deer.mp4\",\n",
    "        model_path=\"models/best.pt\",\n",
    "        #csv_path=\"\",\n",
    "        out_path=\"object_counting_output.avi\",\n",
    "        line_points=[(320, 560), (1820, 540)],\n",
    "        draw=True\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
